<!DOCTYPE html>
<html lang="en">
<head>
          <title>DatasFrame</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
        <link rel="stylesheet" href="./theme/css/main.css" />
        <script src="//code.jquery.com/jquery-2.2.2.min.js"></script>




</head>

<body id="index" class="home">
    <nav>
      <a href=".">Home | </a>
      <a href="/archives.html">Archive | </a>
      <a href="/categories.html">Categories | </a>
      <a href="/pages/about.html">About | </a>
      <a href="/feeds/all.rss.xml">RSS</a>
    </nav>

<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="./tackling the cps.html" rel="bookmark"
         title="Permalink to Tackling the CPS">Tackling the CPS</a></h2>
 
  </header>
  <footer class="post-info">
    <abbr class="published" title="2014-01-27T12:00:00-06:00">
      Mon 27 January 2014
    </abbr>
    <address class="vcard author">
      By           <a class="url fn" href="./author/tom-augspurger.html">Tom Augspurger</a>
    </address>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>Before diving in, you should know a bit about the data. I was working with the monthly microdata files from the CPS. These are used to estimate things like the unemployment rate you see reported every month. Since around 2002, about 60,000 households are interviewed 8 times each over a year. They're interviewed for 4 months, take 4 months off, and are interviewed for 4 more months after the break. Questions are asked about demographics, education, economic activity (and more).</p>
<h2>Fetching the Data</h2>
<p>This was probably the easiest part of the whole project.
The <a href="http://www.nber.org/data/cps_basic.html">CPS website</a> has links to all the monthly files and some associated data dictionaries describing the layout of the files (more on this later).</p>
<p>In <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/monthly_data_downloader.py"><code>monthly_data_downloader.py</code></a> I fetch files from the CPS website and save them locally.  A common trial was the CPS's inconsistency. Granted, consistency and backwards compatibility are difficult, and sometimes there are valid reasons for making a break, but at times the changes felt excessive and random. Anyway for January 1976 to December 2009 the URL pattern is <code>http://www.nber.org/cps-basic/cpsb****.Z</code>, and from January 2010 on its <code>http://www.nber.org/cps-basic/jan10</code>.</p>
<p>If you're curious the python regex used to match those two patterns is <code>re.compile(r'cpsb\d{4}.Z|\w{3}\d{2}pub.zip|\.[ddf,asc]$')</code>. Yes that's much clearer.</p>
<p>I used python's builtin <a href="http://docs.python.org/2/library/urllib2.html"><code>urllib2</code></a> to fetch the site contents and parse with <code>lxml</code>. You should <em>really</em> just use <a href="http://docs.python-requests.org/en/latest/">requests</a>, instead of <code>urllib2</code> but I wanted to keep dependencies for my project slim (I gave up on this hope later).</p>
<p>A common pattern I used was to parse all of the links on a website, filter out the ones I don't want, and do something with the ones I do want. Here's an example:</p>
<div class="codehilite"><pre><span></span><span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">ifilter</span><span class="p">(</span><span class="n">partial_matcher</span><span class="p">,</span> <span class="n">root</span><span class="o">.</span><span class="n">iterlinks</span><span class="p">()):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_fname</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">link</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">_fname</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">existing</span> <span class="o">=</span> <span class="n">_exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">existing</span><span class="p">:</span>
        <span class="n">downloader</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">out_dir</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Added {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fname</span><span class="p">))</span>
</pre></div>


<p><code>root</code> is just the parsed html from <code>lxml.parse</code>. <code>iterlinks()</code> returns an iterable, which I filter through <code>partial_matcher</code>, a function that matches the filename patterns I described above. Iterators are my favorite feature of Python (not that they are exclusive to Python; I just love easy and flexible they are). The idea of having a list, filtering it, and applying a function to the ones you want is so simple, but so generally applicable. I could have even been a bit more functional and written it as <code>imap(downloader(ifilter(existing, ifilter(partial_matcher, root.iterlinks()))</code>. Lovely in its own way!</p>
<p>I do some checking to see if the file exists (so that I can easily download new months). If it is a new month, the filename gets passed to <code>downloader</code>:</p>
<div class="codehilite"><pre><span></span>def downloader(link, out_dir, dl_base=&quot;http://www.nber.org/cps-basic/&quot;):
    &quot;&quot;&quot;
    Link is a str like cpsmar06.zip; It is both the end of the url
    and the filename to be used.
    &quot;&quot;&quot;
    content = urllib2.urlopen(dl_base + link)
    with open(out_dir + link, &#39;w&#39;) as f:
        f.write(content.read())
</pre></div>


<p>This reads the data from at url and write writes it do a file.</p>
<p>Finally, I run <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/renamer.py"><code>renamer.py</code></a> to clean up the file names. Just because the CPS is inconsistent doesn't mean that we have to be.</p>
<p>In the <a href="http://tomaugspurger.github.io/blog/2014/02/04/tackling%20the%20cps%20(part%202)/">next post</a> I'll describe parsing the files we just downloaded.</p>
  </div><!-- /.entry-content -->
</section>

    <footer>
      <p>&copy; Tom Augspurger </p>
    </footer>
  </main>

</body>
</html>