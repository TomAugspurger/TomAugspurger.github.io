<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>pandas on Tom's Blog</title><link>https://tomaugspurger.github.io/tags/pandas/</link><description>Recent content in pandas on Tom's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 01 Apr 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://tomaugspurger.github.io/tags/pandas/index.xml" rel="self" type="application/rss+xml"/><item><title>Maintaining Performance</title><link>https://tomaugspurger.github.io/posts/performance-regressions/</link><pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/performance-regressions/</guid><description>As pandas&amp;rsquo; documentation claims: pandas provides high-performance data structures. But how do we verify that the claim is correct? And how do we ensure that it stays correct over many releases. This post describes
pandas&amp;rsquo; current setup for monitoring performance My personal debugging strategy for understanding and fixing performance regressions when they occur. I hope that the first section topic is useful for library maintainers and the second topic is generally useful for people writing performance-sensitive code.</description></item><item><title>Moral Philosophy for pandas or: What is `.values`?</title><link>https://tomaugspurger.github.io/posts/pandas-moral-philosophy/</link><pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/pandas-moral-philosophy/</guid><description>The other day, I put up a Twitter poll asking a simple question: What&amp;rsquo;s the type of series.values?
Pop Quiz! What are the possible results for the following:
&amp;gt;&amp;gt;&amp;gt; type(pandas.Series.values)
&amp;mdash; Tom Augspurger (@TomAugspurger) August 6, 2018 I was a bit limited for space, so I&amp;rsquo;ll expand on the options here. Choose as many as you want.
NumPy ndarray pandas Categorical (or all of the above) An Index or any of it&amp;rsquo;s subclasses (DatetimeIndex, CategoricalIndex, RangeIndex, etc.</description></item><item><title>Modern Pandas (Part 8): Scaling</title><link>https://tomaugspurger.github.io/posts/modern-8-scaling/</link><pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-8-scaling/</guid><description>This is part 1 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling As I sit down to write this, the third-most popular pandas question on StackOverflow covers how to use pandas for large datasets. This is in tension with the fact that a pandas DataFrame is an in memory container. You can&amp;rsquo;t have a DataFrame larger than your machine&amp;rsquo;s RAM.</description></item><item><title>Extension Arrays for Pandas</title><link>https://tomaugspurger.github.io/posts/pandas-extension-arrays/</link><pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/pandas-extension-arrays/</guid><description>This is a status update on some enhancements for pandas. The goal of the work is to store things that are sufficiently array-like in a pandas DataFrame, even if they aren&amp;rsquo;t a regular NumPy array. Pandas already does this in a few places for some blessed types (like Categorical); we&amp;rsquo;d like to open that up to anybody.
A couple months ago, a client came to Anaconda with a problem: they have a bunch of IP Address data that they&amp;rsquo;d like to work with in pandas.</description></item><item><title>Modern Pandas (Part 7): Timeseries</title><link>https://tomaugspurger.github.io/posts/modern-7-timeseries/</link><pubDate>Fri, 13 May 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-7-timeseries/</guid><description>This is part 7 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Timeseries Pandas started out in the financial world, so naturally it has strong timeseries support.
The first half of this post will look at pandas&amp;rsquo; capabilities for manipulating time series data. The second half will discuss modelling time series data with statsmodels.
%matplotlib inline import os import numpy as np import pandas as pd import pandas_datareader.</description></item><item><title>Modern Pandas (Part 6): Visualization</title><link>https://tomaugspurger.github.io/posts/modern-6-visualization/</link><pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-6-visualization/</guid><description>This is part 6 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Visualization and Exploratory Analysis A few weeks ago, the R community went through some hand-wringing about plotting packages. For outsiders (like me) the details aren&amp;rsquo;t that important, but some brief background might be useful so we can transfer the takeaways to Python. The competing systems are &amp;ldquo;base R&amp;rdquo;, which is the plotting system built into the language, and ggplot2, Hadley Wickham&amp;rsquo;s implementation of the grammar of graphics.</description></item><item><title>Modern Pandas (Part 5): Tidy Data</title><link>https://tomaugspurger.github.io/posts/modern-5-tidy/</link><pubDate>Fri, 22 Apr 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-5-tidy/</guid><description>This is part 5 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Reshaping &amp;amp; Tidy Data Structuring datasets to facilitate analysis (Wickham 2014)
So, you&amp;rsquo;ve sat down to analyze a new dataset. What do you do first?
In episode 11 of Not So Standard Deviations, Hilary and Roger discussed their typical approaches. I&amp;rsquo;m with Hilary on this one, you should make sure your data is tidy.</description></item><item><title>Modern Panadas (Part 3): Indexes</title><link>https://tomaugspurger.github.io/posts/modern-3-indexes/</link><pubDate>Mon, 11 Apr 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-3-indexes/</guid><description>This is part 3 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Indexes can be a difficult concept to grasp at first. I suspect this is partly becuase they&amp;rsquo;re somewhat peculiar to pandas. These aren&amp;rsquo;t like the indexes put on relational database tables for performance optimizations. Rather, they&amp;rsquo;re more like the row_labels of an R DataFrame, but much more capable.</description></item><item><title>Modern Pandas (Part 4): Performance</title><link>https://tomaugspurger.github.io/posts/modern-4-performance/</link><pubDate>Fri, 08 Apr 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-4-performance/</guid><description>This is part 4 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Wes McKinney, the creator of pandas, is kind of obsessed with performance. From micro-optimizations for element access, to embedding a fast hash table inside pandas, we all benefit from his and others&amp;rsquo; hard work. This post will focus mainly on making efficient use of pandas and NumPy.</description></item><item><title>Modern Pandas (Part 2): Method Chaining</title><link>https://tomaugspurger.github.io/posts/method-chaining/</link><pubDate>Mon, 04 Apr 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/method-chaining/</guid><description>This is part 2 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Method Chaining Method chaining, where you call methods on an object one after another, is in vogue at the moment. It&amp;rsquo;s always been a style of programming that&amp;rsquo;s been possible with pandas, and over the past several releases, we&amp;rsquo;ve added methods that enable even more chaining.</description></item><item><title>Modern Pandas (Part 1)</title><link>https://tomaugspurger.github.io/posts/modern-1-intro/</link><pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/modern-1-intro/</guid><description>This is part 1 in my series on writing modern idiomatic pandas.
Modern Pandas Method Chaining Indexes Fast Pandas Tidy Data Visualization Time Series Scaling Effective Pandas Introduction This series is about how to make effective use of pandas, a data analysis library for the Python programming language. It&amp;rsquo;s targeted at an intermediate level: people who have some experience with pandas, but are looking to improve.
Prior Art There are many great resources for learning pandas; this is not one of them.</description></item><item><title>Practical Pandas Part 3 - Exploratory Data Analysis</title><link>https://tomaugspurger.github.io/posts/pp03/</link><pubDate>Tue, 16 Sep 2014 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/pp03/</guid><description>Welcome back. As a reminder:
In part 1 we got dataset with my cycling data from last year merged and stored in an HDF5 store In part 2 we did some cleaning and augmented the cycling data with data from http://forecast.io. You can find the full source code and data at this project&amp;rsquo;s GitHub repo.
Today we&amp;rsquo;ll use pandas, seaborn, and matplotlib to do some exploratory data analysis. For fun, we&amp;rsquo;ll make some maps at the end using folium.</description></item><item><title>Practical Pandas Part 2 - More Tidying, More Data, and Merging</title><link>https://tomaugspurger.github.io/posts/pp02/</link><pubDate>Thu, 04 Sep 2014 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/pp02/</guid><description>This is Part 2 in the Practical Pandas Series, where I work through a data analysis problem from start to finish.
It&amp;rsquo;s a misconception that we can cleanly separate the data analysis pipeline into a linear sequence of steps from
data acqusition data tidying exploratory analysis model building production As you work through a problem you&amp;rsquo;ll realize, &amp;ldquo;I need this other bit of data&amp;rdquo;, or &amp;ldquo;this would be easier if I stored the data this way&amp;rdquo;, or more commonly &amp;ldquo;strange, that&amp;rsquo;s not supposed to happen&amp;rdquo;.</description></item><item><title>Practical Pandas Part 1 - Reading the Data</title><link>https://tomaugspurger.github.io/posts/pp01/</link><pubDate>Tue, 26 Aug 2014 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/pp01/</guid><description>This is the first post in a series where I&amp;rsquo;ll show how I use pandas on real-world datasets.
For this post, we&amp;rsquo;ll look at data I collected with Cyclemeter on my daily bike ride to and from school last year. I had to manually start and stop the tracking at the beginning and end of each ride. There may have been times where I forgot to do that, so we&amp;rsquo;ll see if we can find those.</description></item><item><title>dplyr and pandas</title><link>https://tomaugspurger.github.io/posts/dplry-pandas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/dplry-pandas/</guid><description>This notebook compares pandas and dplyr. The comparison is just on syntax (verbage), not performance. Whether you&amp;rsquo;re an R user looking to switch to pandas (or the other way around), I hope this guide will help ease the transition.
We&amp;rsquo;ll work through the introductory dplyr vignette to analyze some flight data.
I&amp;rsquo;m working on a better layout to show the two packages side by side. But for now I&amp;rsquo;m just putting the dplyr code in a comment above each python call.</description></item><item><title>Tidy Data in Action</title><link>https://tomaugspurger.github.io/posts/tidy-data-in-action/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/tidy-data-in-action/</guid><description>Hadley Whickham wrote a famous paper (for a certain definition of famous) about the importance of tidy data when doing data analysis. I want to talk a bit about that, using an example from a StackOverflow post, with a solution using pandas. The principles of tidy data aren&amp;rsquo;t language specific.
A tidy dataset must satisfy three criteria (page 4 in Whickham&amp;rsquo;s paper):
Each variable forms a column. Each observation forms a row.</description></item><item><title>Using Python to tackle the CPS</title><link>https://tomaugspurger.github.io/posts/tackling-the-cps/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/tackling-the-cps/</guid><description>The Current Population Survey is an important source of data for economists. It&amp;rsquo;s modern form took shape in the 70&amp;rsquo;s and unfortunately the data format and distribution shows its age. Some centers like IPUMS have attempted to put a nicer face on accessing the data, but they haven&amp;rsquo;t done everything yet. In this series I&amp;rsquo;ll describe methods I used to fetch, parse, and analyze CPS data for my second year paper.</description></item><item><title>Using Python to tackle the CPS (Part 2)</title><link>https://tomaugspurger.github.io/posts/tackling-the-cps-part-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/tackling-the-cps-part-2/</guid><description>Last time, we used Python to fetch some data from the Current Population Survey. Today, we&amp;rsquo;ll work on parsing the files we just downloaded.
We downloaded two types of files last time:
CPS monthly tables: a fixed-width format text file with the actual data Data Dictionaries: a text file describing the layout of the monthly tables Our goal is to parse the monthly tables. Here&amp;rsquo;s the first two lines from the unzipped January 1994 file:</description></item><item><title>Using Python to tackle the CPS (Part 3)</title><link>https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/</guid><description>In part 2 of this series, we set the stage to parse the data files themselves.
As a reminder, we have a dictionary that looks like
id length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files.</description></item><item><title>Using Python to tackle the CPS (Part 4)</title><link>https://tomaugspurger.github.io/posts/tackling-the-cps-part-4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tomaugspurger.github.io/posts/tackling-the-cps-part-4/</guid><description>Last time, we got to where we&amp;rsquo;d like to have started: One file per month, with each month laid out the same.
As a reminder, the CPS interviews households 8 times over the course of 16 months. They&amp;rsquo;re interviewed for 4 months, take 8 months off, and are interviewed four more times. So if your first interview was in month $m$, you&amp;rsquo;re also interviewed in months $$m + 1, m + 2, m + 3, m + 12, m + 13, m + 14, m + 15$$.</description></item></channel></rss>