<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>What's Next? (2024 edition) | Tom's Blog</title>
<meta name=keywords content><meta name=description content="I have, as they say, some personal news to share. On Monday I (along with some very talented teammates, see below if you&rsquo;re hiring) was laid off from Microsoft as part of a reorganization. Like my Moving to Microsoft post, I wanted to jot down some of the things I got to work on.
For those of you wondering, the Planetary Computer project does continue, just without me.
Reflections
It should go without saying that all of this was a team effort. I&rsquo;ve been incredibly fortunate to have great teammates over the years, but the team building out the Planetary Computer was especially fantastic.
Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this."><meta name=author content><link rel=canonical href=https://tomaugspurger.net/posts/leaving-microsoft/><link crossorigin=anonymous href=/assets/css/stylesheet.ced21e6d3497ee93fed8f8b357448095840179bd510b5ea0e6013078712e6dd1.css integrity="sha256-ztIebTSX7pP+2PizV0SAlYQBeb1RC16g5gEweHEubdE=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://tomaugspurger.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tomaugspurger.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tomaugspurger.net/favicon-32x32.png><link rel=apple-touch-icon href=https://tomaugspurger.net/apple-touch-icon.png><link rel=mask-icon href=https://tomaugspurger.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tomaugspurger.net/posts/leaving-microsoft/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="What's Next? (2024 edition)"><meta property="og:description" content="I have, as they say, some personal news to share. On Monday I (along with some very talented teammates, see below if you&rsquo;re hiring) was laid off from Microsoft as part of a reorganization. Like my Moving to Microsoft post, I wanted to jot down some of the things I got to work on.
For those of you wondering, the Planetary Computer project does continue, just without me.
Reflections
It should go without saying that all of this was a team effort. I&rsquo;ve been incredibly fortunate to have great teammates over the years, but the team building out the Planetary Computer was especially fantastic.
Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this."><meta property="og:type" content="article"><meta property="og:url" content="https://tomaugspurger.net/posts/leaving-microsoft/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-12T07:00:00-05:00"><meta property="article:modified_time" content="2024-08-12T07:00:00-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="What's Next? (2024 edition)"><meta name=twitter:description content="I have, as they say, some personal news to share. On Monday I (along with some very talented teammates, see below if you&rsquo;re hiring) was laid off from Microsoft as part of a reorganization. Like my Moving to Microsoft post, I wanted to jot down some of the things I got to work on.
For those of you wondering, the Planetary Computer project does continue, just without me.
Reflections
It should go without saying that all of this was a team effort. I&rsquo;ve been incredibly fortunate to have great teammates over the years, but the team building out the Planetary Computer was especially fantastic.
Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tomaugspurger.net/posts/"},{"@type":"ListItem","position":2,"name":"What's Next? (2024 edition)","item":"https://tomaugspurger.net/posts/leaving-microsoft/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"What's Next? (2024 edition)","name":"What\u0027s Next? (2024 edition)","description":"I have, as they say, some personal news to share. On Monday I (along with some very talented teammates, see below if you\u0026rsquo;re hiring) was laid off from Microsoft as part of a reorganization. Like my Moving to Microsoft post, I wanted to jot down some of the things I got to work on.\nFor those of you wondering, the Planetary Computer project does continue, just without me.\nReflections It should go without saying that all of this was a team effort. I\u0026rsquo;ve been incredibly fortunate to have great teammates over the years, but the team building out the Planetary Computer was especially fantastic. Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this.\n","keywords":[],"articleBody":"I have, as they say, some personal news to share. On Monday I (along with some very talented teammates, see below if you’re hiring) was laid off from Microsoft as part of a reorganization. Like my Moving to Microsoft post, I wanted to jot down some of the things I got to work on.\nFor those of you wondering, the Planetary Computer project does continue, just without me.\nReflections It should go without saying that all of this was a team effort. I’ve been incredibly fortunate to have great teammates over the years, but the team building out the Planetary Computer was especially fantastic. Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this.\nI’m a bit uncomfortable with all the navel gazing, but I am glad I did the last one so here goes.\nThe Hub Our initial vision for the Planetary Computer had four main components:\nData (the actual files in Blob Storage, ideally in cloud-optimized formats) APIs (like the STAC API which make the data usable; using raster geospatial data without a STAC API feels barbaric now) Compute Applications (which package all the low level details into reports or tools that are useful to decision makers) Initially, my primary responsibility on the team was to figure out “Compute”. Dan Morris had a nice line around “it shouldn’t require a PhD in remote sensing and a PhD in distributed computing to use this data.”\nAfter fighting with Azure AD and RBAC roles for a few weeks, I had the initial version of the PC Hub up and running. This was a more-or-less stock version of the daskhub helm deployment with a few customizations.\nAside from occasionally updating the container images and banning crypto miners (stealing free compute to burn CPU cycles on a platform built for sustainability takes some hutzpah), that was mostly that. While the JupyterHub + Dask on Kubernetes model isn’t perfect for every use case, it solves a lot of problems. You might still have to know a bit about distributed computing in order to run a large computation, but at least our users didn’t have to fight with Kubernetes (just the Hub admin, me in this case).\nProbably the most valuable aspect of the Hub was having a shared environment where anyone could easily run our Example Notebooks. We also ran several “cloud native geospatial” tutorials on one-off Hubs deployed for a conference.\nThis also gave the opportunity to sketch out an implementation of Yuvi’s kbatch proposal. I didn’t end up having time to follow up on the initial implementation, but I still think there’s room for a very simple way to submit batch Jobs to the same compute powering your interactive JupyterHub sessions.\nstac-vrt Very early on in project1, we had an opportunity to present on the Planetary Computer to Kevin Scott and his team. Our presentation included a short demo applying a Land Use / Land Cover model to some NAIP data. While preparing that, I noticed that doing rioxarray.open_rasterio on a bunch of NAIP COGs was slow. Basically, GDAL had to make an HTTP request to read the COG metadata of each file.\nAfter reading some GitHub issues and Pangeo discussions, I learned about using GDAL VRTs as a potential solution to the problem. Fortunately, our STAC items had all the information needed to build a VRT, and rioxarray already knew how to open VRTs. We just needed a tool to build that VRT. That was stac-vrt.\nI say “was” because similar functionality is now (better) implemented in GDAL itself, stackstac, and odc-stac.\nThis taught me that STAC can be valuable beyond just searching for data. The metadata in the STAC items can be useful during analysis too. Also, as someone who grew up in the open-source Scientific Python Ecosystem, it felt neat to get tools like xarray and Dask in front of the CTO of Microsoft.\ngeoparquet I had a very small hand in getting geoparquet started, connecting Chris Holmes with Joris van den Bossche and the geopandas / geoarrow group. Since then my contributions have been relatively minor, but at least for a while the Planetary Computer could claim to host the most geoparquet data (by count of datasets and volume) than anyone else. Overture Maps probably claims that title now, which is fantastic.\nstac-geoparquet Pretty early on, we had some users with demanding use-cases where the STAC API itself was becoming a bottleneck. We pulled some tricks to speed up their queries, but this showed us there was a need to provide bulk access to the STAC metadata, where the number of items in the result is very large.\nWith a quick afternoon hack, I got a prototype running that converted our STAC items (which live in a Postgres database) to geoparquet (technically, this predated geoparquet!). The generic pieces of that tooling are at https://github.com/stac-utils/stac-geoparquet/ now. Kyle Barron recently made some really nice improvements to the library (moving much of the actually processing down into Apache Arrow), and Pete Gadomski is working on a Rust implementation.\nFor the right workloads, serving large collections of STAC metadata through Parquet (or even better, Delta or Iceberg or some other table format) is indispensable.\nData Pipelines These are less visible externally (except when they break), but a couple years ago I took on more responsibility for the data pipelines that keep data flowing into the Planetary Computer. Broadly speaking, this included\nGetting data from upstream sources to Azure Blob Storage Creating STAC Items for new data and ingesting them into the Postgres database Building and maintaining these pipelines was… challenging. Our APIs or database would occasionally give us issues (especially under load). But the onboarding pipelines required a steady stream of attention, and would also blow up occasionally when the upstream data providers changed something. https://sre.google/sre-book/monitoring-distributed-systems/ is a really handy resource for thinking about how to monitor this type of system. This was a great chance to learn.\npc-id Before we publicly launched the Planetary Computer, we didn’t have a good idea of how we would manage users. We knew that we wanted to role things out somewhat slowly (at least access to the Hub; the data and APIs might have always been anonymously available?). So we knew we needed some kind of sign-up systems, and some sort of identity system that could be used by both our API layer (built on Azure’s API Management service) and our Hub.\nAfter throwing around some ideas (Azure AD B2C? Inviting beta users as Guests in the Microsoft Corp tenant?), I put together the sketch of a Django application that could be the Identity backend for both API Management and the Hub. Users would sign in with their Work or Personal Microsoft Accounts (in the Hub or API Management Dev Portal) and our ID application would check that the user was registered and approved.\nWe added a few bells and whistles to the Admin interface to speed up the approval process, and then more or less didn’t touch it aside from basic maintenance. Django is great. I am by no means a web developer, but it let us get started quickly on a solid foundation.\nOther Highlights xstac: A library for creating STAC metadata for xarray datasets stac-table: A library for creating STAC metadata for geopandas GeoDataFrames Several stactools-packages, to create STAC metadata for specific datasets Many presentations on Cloud Native Geospatial, including at AMS and Cloud Native Geospatial Day There’s lots of STAC here. I’d like to think that we had a hand in shaping how the STAC ecosystem works, especially for more “exotic” datasets like tables and data cubes in NetCDF or Zarr format.\nWhat’s Next? Last time around, I ended things with the exciting announcement that I was moving to Microsoft. This time… I don’t know! This is my first time not having a job lined up, so I’ll hope to spend some time finding the right thing to work on.\nOne thing I’m trying to figure out is how much to stock to place in the geospatial knowledge I’ve picked up over the last four years. I’ve spent a lot of time learning and thinking about geospatial things (though I still cant’t explain the difference between a CRS and Datum). There’s a lot of domain-specific knowledge needed to use these geospatial datasets (too much domain-specificity, in my opinion). We’ll see if that’s useful.\nLike I mentioned above, I wasn’t the only one who was laid off. There are some really talented people on the job market, both more junior and more senior. If you’re looking for someone you can reach me at tom.w.augspurger@gmail.com.\nThanks for reading!\nMatt was the last of the original crew to join. On his first day, we had to break the news that he was presenting to the CTO in a week. ↩︎\n","wordCount":"1477","inLanguage":"en","datePublished":"2024-08-12T07:00:00-05:00","dateModified":"2024-08-12T07:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tomaugspurger.net/posts/leaving-microsoft/"},"publisher":{"@type":"Organization","name":"Tom's Blog","logo":{"@type":"ImageObject","url":"https://tomaugspurger.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tomaugspurger.net/ accesskey=h title="Tom's Blog (Alt + H)">Tom's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://tomaugspurger.net/about/ title=About><span>About</span></a></li><li><a href=https://tomaugspurger.net/archives title=Archive><span>Archive</span></a></li><li><a href=https://tomaugspurger.net/index.xml title=RSS><span>RSS</span></a></li><li><a href=https://tomaugspurger.net/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">What's Next? (2024 edition)</h1><div class=post-meta><span title='2024-08-12 07:00:00 -0500 -0500'>August 12, 2024</span></div></header><div class=post-content><p>I have, as they say, some personal news to share. On Monday I (along with some <em>very</em> talented teammates, see <a href=#whats-next>below</a> if you&rsquo;re hiring) was laid off from Microsoft as part of a reorganization. Like my <a href=/posts/whats-next>Moving to Microsoft</a> post, I wanted to jot down some of the things I got to work on.</p><p>For those of you wondering, the <a href=https://planetarycomputer.microsoft.com>Planetary Computer</a> project <em>does</em> continue, just without me.</p><h2 id=reflections>Reflections<a hidden class=anchor aria-hidden=true href=#reflections>#</a></h2><p>It should go without saying that <em>all</em> of this was a team effort. I&rsquo;ve been incredibly fortunate to have great teammates over the years, but the team building out the <a href=http://planetarycomputer.microsoft.com/>Planetary Computer</a> was especially fantastic.
Just like before, this will be very self-centered and project-focused, overlooking all the other people and work that went into this.</p><p>I&rsquo;m a <em>bit</em> uncomfortable with all the navel gazing, but I am glad I did the last one so here goes.</p><h3 id=the-hub>The Hub<a hidden class=anchor aria-hidden=true href=#the-hub>#</a></h3><p>Our initial vision for the Planetary Computer had four main components:</p><ol><li>Data (the actual files in Blob Storage, ideally in cloud-optimized formats)</li><li>APIs (like the STAC API which make the data usable; using raster geospatial data <em>without</em> a STAC API feels barbaric now)</li><li>Compute</li><li>Applications (which package all the low level details into reports or tools that are useful to decision makers)</li></ol><p>Initially, my primary responsibility on the team was to figure out &ldquo;Compute&rdquo;. <a href=http://dmorris.net>Dan Morris</a> had a nice line around &ldquo;it shouldn&rsquo;t require a PhD in remote sensing <em>and</em> a PhD in distributed computing to use this data.&rdquo;</p><p>After fighting with Azure AD and RBAC roles for a few weeks, I had the initial version of the <a href=https://github.com/Microsoft/planetary-computer-hub>PC Hub</a> up and running. This was a more-or-less stock version of the <a href=https://github.com/dask/helm-chart/blob/main/daskhub/README.md>daskhub</a> helm deployment with a few customizations.</p><p>Aside from occasionally updating the container images and banning crypto miners (stealing free compute to burn CPU cycles on a platform built for sustainability takes some hutzpah), that was mostly that. While the JupyterHub + Dask on Kubernetes model isn&rsquo;t perfect for every use case, it solves a lot of problems. You might still have to know a <em>bit</em> about distributed computing in order to run a large computation, but at least our users didn&rsquo;t have to fight with Kubernetes (just the Hub admin, me in this case).</p><p>Probably the most valuable aspect of the Hub was having a shared environment where anyone could easily run our <a href=https://github.com/microsoft/PlanetaryComptuerExamples>Example Notebooks</a>. We also ran several &ldquo;cloud native geospatial&rdquo; tutorials on one-off Hubs deployed for a conference.</p><p>This also gave the opportunity to sketch out <a href=https://github.com/kbatch-dev/kbatch>an implementation</a> of Yuvi&rsquo;s <a href=https://words.yuvi.in/post/kbatch/>kbatch</a> proposal. I didn&rsquo;t end up having time to follow up on the initial implementation, but I still think there&rsquo;s room for a <em>very simple</em> way to submit batch Jobs to the same compute powering your interactive JupyterHub sessions.</p><h3 id=stac-vrt>stac-vrt<a hidden class=anchor aria-hidden=true href=#stac-vrt>#</a></h3><p><em>Very</em> early on in project<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, we had an opportunity to present on the Planetary Computer to <a href=https://news.microsoft.com/exec/kevin-scott/>Kevin Scott</a> and his team. Our presentation included a short demo applying a Land Use / Land Cover model to some <a href=https://planetarycomputer.microsoft.com/dataset/naip>NAIP data</a>. While preparing that, I noticed that doing <code>rioxarray.open_rasterio</code> on a bunch of NAIP COGs was slow. Basically, GDAL had to make an HTTP request to read the COG metadata of each file.</p><p>After reading some GitHub issues and Pangeo discussions, I learned about using <a href=https://gdal.org/drivers/raster/vrt.html>GDAL VRTs</a> as a potential solution to the problem. Fortunately, our STAC items had all the information needed to build a VRT, and rioxarray already knew how to open VRTs. We just needed a tool to build that VRT. That was <a href=https://github.com/stac-utils/stac-vrt/>stac-vrt</a>.</p><p>I say &ldquo;was&rdquo; because similar functionality is now (better) implemented in <a href=https://gdal.org/drivers/raster/stacit.html>GDAL itself</a>, <a href=https://stackstac.readthedocs.io/en/latest/>stackstac</a>, and <a href=https://odc-stac.readthedocs.io/en/latest/>odc-stac</a>.</p><p>This taught me that STAC can be valuable beyond just searching for data. The metadata in the STAC items can be useful during analysis too. Also, as someone who grew up in the open-source Scientific Python Ecosystem, it felt neat to get tools like xarray and Dask in front of the CTO of Microsoft.</p><h3 id=geoparquet>geoparquet<a hidden class=anchor aria-hidden=true href=#geoparquet>#</a></h3><p>I had a very small hand in getting <a href=https://geoparquet.org>geoparquet</a> started, connecting <a href=https://www.linkedin.com/in/opencholmes/>Chris Holmes</a> with <a href=https://github.com/jorisvandenbossche>Joris van den Bossche</a> and the geopandas / geoarrow group. Since then my contributions have been relatively minor, but at least for a while the Planetary Computer could claim to host the most geoparquet data (by count of datasets and volume) than anyone else. <a href=https://overturemaps.org>Overture Maps</a> probably claims that title now, which is fantastic.</p><h3 id=stac-geoparquet>stac-geoparquet<a hidden class=anchor aria-hidden=true href=#stac-geoparquet>#</a></h3><p>Pretty early on, we had some users with demanding use-cases where the STAC API itself was becoming a bottleneck. We pulled some tricks to speed up their queries, but this showed us there was a need to provide bulk access to the STAC metadata, where the number of items in the result is very large.</p><p>With a quick afternoon hack, I got a prototype running that converted our STAC items (which live in a Postgres database) to geoparquet (technically, this predated geoparquet!). The generic pieces of that tooling are at <a href=https://github.com/stac-utils/stac-geoparquet/>https://github.com/stac-utils/stac-geoparquet/</a> now. Kyle Barron recently made some really nice improvements to the library (moving much of the actually processing down into Apache Arrow), and Pete Gadomski is working on a <a href=https://github.com/stac-utils/stac-rs/pull/256>Rust implementation</a>.</p><p>For the right workloads, serving large collections of STAC metadata through Parquet (or even better, Delta or Iceberg or some other table format) is indispensable.</p><h3 id=data-pipelines>Data Pipelines<a hidden class=anchor aria-hidden=true href=#data-pipelines>#</a></h3><p>These are less visible externally (except when they break), but a couple years ago I took on more responsibility for the data pipelines that keep data flowing into the Planetary Computer. Broadly speaking, this included</p><ol><li>Getting data from upstream sources to Azure Blob Storage</li><li>Creating STAC Items for new data and ingesting them into the Postgres database</li></ol><p>Building and maintaining these pipelines was&mldr; challenging. Our APIs or database would occasionally give us issues (especially under load). But the onboarding pipelines required a steady stream of attention, and would also blow up occasionally when the upstream data providers changed something. <a href=https://sre.google/sre-book/monitoring-distributed-systems/>https://sre.google/sre-book/monitoring-distributed-systems/</a> is a really handy resource for thinking about how to monitor this type of system. This was a great chance to learn.</p><h3 id=pc-id>pc-id<a hidden class=anchor aria-hidden=true href=#pc-id>#</a></h3><p>Before we publicly launched the Planetary Computer, we didn&rsquo;t have a good idea of how we would manage users. We knew that we wanted to role things out somewhat slowly (at least access to the Hub; the data and APIs might have always been anonymously available?). So we knew we needed some kind of sign-up systems, and some sort of identity system that could be used by both our API layer (built on Azure&rsquo;s API Management service) and our Hub.</p><p>After throwing around some ideas (Azure AD B2C? Inviting beta users as Guests in the Microsoft Corp tenant?), I put together the sketch of a Django application that could be the Identity backend for both API Management and the Hub. Users would sign in with their Work or Personal Microsoft Accounts (in the Hub or API Management Dev Portal) and our ID application would check that the user was registered and approved.</p><p>We added a few bells and whistles to the Admin interface to speed up the approval process, and then more or less didn&rsquo;t touch it aside from basic maintenance. Django is <em>great</em>. I am by no means a web developer, but it let us get started quickly on a solid foundation.</p><h3 id=other-highlights>Other Highlights<a hidden class=anchor aria-hidden=true href=#other-highlights>#</a></h3><ul><li><a href=https://github.com/stac-utils/xstac>xstac</a>: A library for creating STAC metadata for xarray datasets</li><li><a href=https://github.com/stac-utils/stac-table>stac-table</a>: A library for creating STAC metadata for geopandas GeoDataFrames</li><li>Several <a href=https://github.com/stactools-packages/>stactools-packages</a>, to create STAC metadata for specific datasets</li><li>Many presentations on Cloud Native Geospatial, including at <a href=https://github.com/TomAugspurger/pc-ams>AMS</a> and <a href=https://github.com/TomAugspurger/pc-cng-outreach-2022>Cloud Native Geospatial Day</a></li></ul><p>There&rsquo;s lots of STAC here. I&rsquo;d like to think that we had a hand in shaping how the STAC ecosystem works, especially for more &ldquo;exotic&rdquo; datasets like tables and data cubes in NetCDF or Zarr format.</p><h3 id=whats-next>What&rsquo;s Next?<a hidden class=anchor aria-hidden=true href=#whats-next>#</a></h3><p>Last time around, I ended things with the exciting announcement that I was moving to Microsoft. This time&mldr; I don&rsquo;t know! This is my first time not having a job lined up, so I&rsquo;ll hope to spend some time finding the right thing to work on.</p><p>One thing I&rsquo;m trying to figure out is how much to stock to place in the geospatial knowledge I&rsquo;ve picked up over the last four years. I&rsquo;ve spent a lot of time learning and thinking about geospatial things (though I still cant&rsquo;t explain the difference between a CRS and Datum). There&rsquo;s a lot of domain-specific knowledge needed to use these geospatial datasets (too much domain-specificity, in my opinion). We&rsquo;ll see if that&rsquo;s useful.</p><p>Like I mentioned above, I wasn&rsquo;t the only one who was laid off. There are some really talented people on the job market, both more junior and more senior. If you&rsquo;re looking for someone you can reach me at <a href=mailto:tom.w.augspurger@gmail.com><a href=mailto:tom.w.augspurger@gmail.com>tom.w.augspurger@gmail.com</a></a>.</p><p>Thanks for reading!</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Matt was the last of the original crew to join. On his first day, we had to break the news that he was presenting to the CTO in a week.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://tomaugspurger.net/>Tom's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><a rel=me href=https://mastodon.social/@TomAugspurger></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>