<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cloud Native Geospatial Conference (2025) | Tom's Blog</title>
<meta name=keywords content><meta name=description content="On Thursday, I presented a talk, GPU Accelerated Cloud-Native Geospatial, at the
inaugural Cloud-Native Geospatial Conference (slides here). This post will
give an overview of the talk and some background on the prep. But first I wanted
to say a bit about the conference itself.
The organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a
fantastic job putting on the event. I only have the smallest experience with
helping run a conference, but I know it&rsquo;s a ton of work. They did a great job
hosting this first run of conference."><meta name=author content><link rel=canonical href=https://tomaugspurger.net/posts/cng-forum-2025/><link crossorigin=anonymous href=/assets/css/stylesheet.ced21e6d3497ee93fed8f8b357448095840179bd510b5ea0e6013078712e6dd1.css integrity="sha256-ztIebTSX7pP+2PizV0SAlYQBeb1RC16g5gEweHEubdE=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://tomaugspurger.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tomaugspurger.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tomaugspurger.net/favicon-32x32.png><link rel=apple-touch-icon href=https://tomaugspurger.net/apple-touch-icon.png><link rel=mask-icon href=https://tomaugspurger.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tomaugspurger.net/posts/cng-forum-2025/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Cloud Native Geospatial Conference (2025)"><meta property="og:description" content="On Thursday, I presented a talk, GPU Accelerated Cloud-Native Geospatial, at the
inaugural Cloud-Native Geospatial Conference (slides here). This post will
give an overview of the talk and some background on the prep. But first I wanted
to say a bit about the conference itself.
The organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a
fantastic job putting on the event. I only have the smallest experience with
helping run a conference, but I know it&rsquo;s a ton of work. They did a great job
hosting this first run of conference."><meta property="og:type" content="article"><meta property="og:url" content="https://tomaugspurger.net/posts/cng-forum-2025/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-04T00:00:00-06:00"><meta property="article:modified_time" content="2025-05-04T00:00:00-06:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cloud Native Geospatial Conference (2025)"><meta name=twitter:description content="On Thursday, I presented a talk, GPU Accelerated Cloud-Native Geospatial, at the
inaugural Cloud-Native Geospatial Conference (slides here). This post will
give an overview of the talk and some background on the prep. But first I wanted
to say a bit about the conference itself.
The organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a
fantastic job putting on the event. I only have the smallest experience with
helping run a conference, but I know it&rsquo;s a ton of work. They did a great job
hosting this first run of conference."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tomaugspurger.net/posts/"},{"@type":"ListItem","position":2,"name":"Cloud Native Geospatial Conference (2025)","item":"https://tomaugspurger.net/posts/cng-forum-2025/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cloud Native Geospatial Conference (2025)","name":"Cloud Native Geospatial Conference (2025)","description":"On Thursday, I presented a talk, GPU Accelerated Cloud-Native Geospatial, at the inaugural Cloud-Native Geospatial Conference (slides here). This post will give an overview of the talk and some background on the prep. But first I wanted to say a bit about the conference itself.\nThe organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a fantastic job putting on the event. I only have the smallest experience with helping run a conference, but I know it\u0026rsquo;s a ton of work. They did a great job hosting this first run of conference.\n","keywords":[],"articleBody":"On Thursday, I presented a talk, GPU Accelerated Cloud-Native Geospatial, at the inaugural Cloud-Native Geospatial Conference (slides here). This post will give an overview of the talk and some background on the prep. But first I wanted to say a bit about the conference itself.\nThe organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a fantastic job putting on the event. I only have the smallest experience with helping run a conference, but I know it’s a ton of work. They did a great job hosting this first run of conference.\nThe conference was split into three tracks:\nOn-ramp to Cloud-Native Geospatial (organized by Dr. Julia Wagemann from thriveGEO) Cloud-Native Geospatial in Practice (organized by Aimee Barciauskas from Development Seed) Building Resilient Data Infrastructure Ecosystems (organized by Dr. Brianna Pagán, also from Development Seed) Each of the track leaders did a great job programming their session. As tends to happen at these multi-track conferences, my only complaint is that there were too many interesting talks to choose from. Fortunately, the sessions were recorded and will be posted online. I spent most of my time bouncing between Cloud-Native Geospatial in Practice and On-ramp to Cloud-native Geospatial, but caught a couple talks from the Building Resilient Data Ecosystems track.\nMy main goal at the conference was to listen to peoples’ use-cases, with the hope of identifying workloads that might benefit from GPU optimization. If you have a geospatial workload that you want to GPU-optimize, please contact me.\nMy Talk I pitched this talk about two months into my tenure at NVIDIA, which is to say about two months into my really using GPUs. In some ways, this made things awkward: here I am, by no means a CUDA expert, in front of a room telling people how they ought to be doing things. On the other hand, it’s a strength. I’m clearly not subject to the curse of expertise when it comes to GPUs, so I can empathize with what ended up being my intended audience: people who are new to GPUs and wondering if and where they can be useful for achieving their goals.\nWhile preparing, I had some high hopes for doing deep-dives on a few geospatial workloads (e.g. Radiometric Terrain Correction for SAR data, pytorch / torchgeo / xbatcher dataloaders and preprocessing). But between the short talk duration, running out of prep time, and my general newness to GPUs, the talk ended up being fairly introductory and high-level. I think that’s OK.\nGPUs are Fast This was a fun little demo of a “quadratic means” example I took from the Pangeo forum. The hope was to get the room excited and impressed at just how fast GPUs can be. In it, we optimized the runtime of the computation from about 3 seconds on the CPU to about 20 ms on the GPU (via a one-line change to use CuPy).\nFor fun, we optimized it even further to just 4.5 ms by writing a hand-optimized CUDA to use some shared memory tricks and avoid repeated memory accesses.\nYou can see the full demo at https://github.com/TomAugspurger/gpu-cng-2025. I wish now that I had included more geospatial-focused demos. But the talk was only 15-20 minutes and already packed.\nGetting Started with GPU programming There is a ton of software written for NVIDIA chips. Before joining NVIDIA, I didn’t appreciate just how complex these chips are. NVIDIA, especially via RAPIDS, offers a bunch of relatively easy ways to get started.\nThis slide from Jacob Tomlinson’s PyData Global talk showcases the various “swim lanes” when it comes to programming NVIDIA chips from Python:\nThis built nicely off the demo, where we saw two of those swim lanes in action.\nThe other part lowering the barrier of entry is the cloud. Being programmable, a GPU is just an API call away (assuming you’re already set up on one of the clouds providing GPUs).\nThe I/O Problem From there, we took a very high level overview of some geospatial workloads. Each loads some data (which we assumed came from Blob Storage), computed some result, and stored that result. For example, a cloud-free mosaic from some Sentinel-2 imagery:\nI’m realizing now that I should have included a vector data example, perhaps loading an Overture Maps geoparquet file and doing a geospatial join.\nAnyway, the point was to introduce some high-level concepts that we can use to identify workloads amenable to GPU acceleration. First, we looked at a workloads through time, which differ in how I/O vs. compute intensive they are.\nFor example, an I/O-bound workload:\nContrast that with a (mostly) CPU-bound workload:\nTrying to GPU-accelerate the I/O-bound workload will only bring disappointment: even if you manage to speed up the compute portion, it’s such a small portion of the overall runtime to not make a meaningful difference.\nBut GPU-accelerating the compute-bound workload, on the other hand, can lead to to a nice speedup:\nA few things are worth emphasizing:\nYou need to profile your workload to understand where time is being spent. You might be able to turn an I/O bound problem into a compute bound problem by optimizing it (choosing a better file format, placing your compute next to the storage, choosing a faster library for I/O, parallelization, etc.) I’m implying that “I/O” is just sitting around waiting on the network. In reality, some of I/O will be spent doing “compute” things (like parsing and decompressing bytes.) And those portions of I/O can be GPU accelerated. I glossed over the “memory barrier” at this point in the talk, but returned to it later. There are again libraries (like KvikIO) that can help with this. Pipelining Some (most?) problems can be broken into smaller units of work and, potentially, parallelized. By breaking the larger problem into smaller pieces, we have the opportunity to optimize the throughput of our workload through pipelining.\nPipelining lets us overlap various parts of the workload that are using different parts of the system. For example I/O, which is mostly exercising the network, can be pipelined with computation, which is mostly exercising the GPU. First, we look at some poor pipelining:\nThe workload serially reads data, computes the result, and writes the output. This is inefficient: when you’re reading or writing data the GPU is idle (indeed, the CPU is mostly idle too, since it’s waiting for bytes to move over the network). And when you’re computing the result, the CPU (and network) are idle. This manifests as low utilization of the GPU, CPU, and network.\nThis second image shows good pipelining:\nWe’ve set up our program to read, compute, and write batches in parallel. We achieve high utilization of the GPU, CPU, and network.\nThis general concept can apply to CPU-only systems, especially multi-core systems. But the pain of low resource utilization is more pronounced with GPUs, which tend to be more expensive.\nNow, this is a massively oversimplified example where the batches of work happen to be nicely sized and the workload doesn’t require an coordination across batches. But, with effort, the technique can be applied to a wide range of problems.\nMemory Bandwidth This section was pressed for time, but I really wanted to at least touch on one of the first things you’ll hit when doing data analysis on the GPU: moving data from host to device memory is relatively slow.\nIn the talk, I mostly just emphasized the benefits of leaving data on the GPU. The memory hierarchy diagram from the Flash Attention paper gave a nice visual representation of the tradeoff between bandwidth and size the different tiers give (I’d briefly mentioned the SRAM tier during the demo, since our most optimized version used SRAM).\nBut as I mentioned in the talk, most people won’t be interacting with the memory hierarchy beyond minimizing transfers between the host and device.\nReach Out As I mentioned earlier my main goal attending the conference was to hear what the missing pieces of the GPU-accelerated geospatial landscape are (and to catch up with the wonderful members of this community). Reach out with any feedback you might have.\n","wordCount":"1348","inLanguage":"en","datePublished":"2025-05-04T00:00:00-06:00","dateModified":"2025-05-04T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tomaugspurger.net/posts/cng-forum-2025/"},"publisher":{"@type":"Organization","name":"Tom's Blog","logo":{"@type":"ImageObject","url":"https://tomaugspurger.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tomaugspurger.net/ accesskey=h title="Tom's Blog (Alt + H)">Tom's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://tomaugspurger.net/about/ title=About><span>About</span></a></li><li><a href=https://tomaugspurger.net/archives title=Archive><span>Archive</span></a></li><li><a href=https://tomaugspurger.net/index.xml title=RSS><span>RSS</span></a></li><li><a href=https://tomaugspurger.net/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Cloud Native Geospatial Conference (2025)</h1><div class=post-meta><span title='2025-05-04 00:00:00 -0600 -0600'>May 4, 2025</span></div></header><div class=post-content><p>On Thursday, I presented a talk, <em>GPU Accelerated Cloud-Native Geospatial</em>, at the
inaugural Cloud-Native Geospatial Conference (<a href=https://tomaugspurger.net/assets/gpu-accelerated-cng.pdf>slides</a> here). This post will
give an overview of the talk and some background on the prep. But first I wanted
to say a bit about the conference itself.</p><p>The organizers (Michelle Roby, Jed Sundell, and others from Radiant Earth) did a
fantastic job putting on the event. I only have the smallest experience with
helping run a conference, but I know it&rsquo;s a ton of work. They did a great job
hosting this first run of conference.</p><p>The conference was split into three tracks:</p><ol><li>On-ramp to Cloud-Native Geospatial (organized by <a href=https://www.linkedin.com/in/julia-wagemann/>Dr. Julia Wagemann</a> from
thriveGEO)</li><li>Cloud-Native Geospatial in Practice (organized by <a href=https://www.linkedin.com/in/abarciauskas/>Aimee Barciauskas</a> from
Development Seed)</li><li>Building Resilient Data <del>Infrastructure</del> Ecosystems (organized by <a href=https://www.linkedin.com/in/brianna-r-pag%C3%A1n-phd-8a49a46b/>Dr. Brianna
Pagán</a>, also from Development Seed)</li></ol><p>Each of the track leaders did a great job programming their session. As tends to
happen at these multi-track conferences, my only complaint is that there were
too many interesting talks to choose from. Fortunately, the sessions were
recorded and will be posted online. I spent most of my time bouncing between
Cloud-Native Geospatial in Practice and On-ramp to Cloud-native Geospatial, but
caught a couple talks from the Building Resilient Data Ecosystems track.</p><p>My main goal at the conference was to listen to peoples&rsquo; use-cases, with the
hope of identifying workloads that might benefit from GPU optimization. If <em>you</em>
have a geospatial workload that you want to GPU-optimize, please <a href=mailto:toaugspurger@nvidia.com>contact
me</a>.</p><h2 id=my-talk>My Talk<a hidden class=anchor aria-hidden=true href=#my-talk>#</a></h2><p>I pitched this talk about two months into my tenure at NVIDIA, which is to say
about two months into my really using GPUs. In some ways, this made things
awkward: here I am, by no means a CUDA expert, in front of a room telling people
how they ought to be doing things. On the other hand, it&rsquo;s a strength. I&rsquo;m
clearly not subject to the curse of expertise when it comes to GPUs, so I can
empathize with what ended up being my intended audience: people who are new to
GPUs and wondering if and where they can be useful for achieving their goals.</p><p>While preparing, I had some high hopes for doing deep-dives on a few geospatial
workloads (e.g. Radiometric Terrain Correction for SAR data, pytorch / torchgeo
/ xbatcher dataloaders and preprocessing). But between the short talk duration,
running out of prep time, and my general newness to GPUs, the talk ended up
being fairly introductory and high-level. I think that&rsquo;s OK.</p><h3 id=gpus-are-fast>GPUs are Fast<a hidden class=anchor aria-hidden=true href=#gpus-are-fast>#</a></h3><p>This was a fun little demo of a &ldquo;quadratic means&rdquo; example I took from the
<a href=https://discourse.pangeo.io/>Pangeo forum</a>. The hope was to get the room excited and impressed at just how
fast GPUs can be. In it, we optimized the runtime of the computation from about
3 seconds on the CPU to about 20 ms on the GPU (via a one-line change to use
<a href=https://cupy.dev/>CuPy</a>).</p><p>For fun, we optimized it even further to just 4.5 ms by writing a hand-optimized
CUDA to use some shared memory tricks and avoid repeated memory accesses.</p><p>You can see the full demo at <a href=https://github.com/TomAugspurger/gpu-cng-2025>https://github.com/TomAugspurger/gpu-cng-2025</a>. I
wish now that I had included more geospatial-focused demos. But the talk was
only 15-20 minutes and already packed.</p><h3 id=getting-started-with-gpu-programming>Getting Started with GPU programming<a hidden class=anchor aria-hidden=true href=#getting-started-with-gpu-programming>#</a></h3><p>There is a <em>ton</em> of software written for NVIDIA chips. Before joining NVIDIA, I
didn&rsquo;t appreciate just how complex these chips are. NVIDIA, especially via
RAPIDS, offers a bunch of relatively easy ways to get started.</p><p>This slide from Jacob Tomlinson&rsquo;s PyData Global
<a href=https://global2024.pydata.org/cfp/talk/BUC3GV/>talk</a> showcases the various
&ldquo;swim lanes&rdquo; when it comes to programming NVIDIA chips from Python:</p><p><img loading=lazy src=https://github.com/user-attachments/assets/0b0aeda2-6cdc-4946-9b99-3dce73776f0f alt="The &ldquo;Swim Lanes&rdquo; for getting started with GPUs. From easiest to use (zero code change) to maximum performance (C++ CUDA kernels)"></p><p>This built nicely off the demo, where we saw two of those swim lanes in action.</p><p>The other part lowering the barrier of entry is the cloud. Being programmable, a
GPU is just an API call away (assuming you&rsquo;re already set up on one of the
clouds providing GPUs).</p><h3 id=the-io-problem>The I/O Problem<a hidden class=anchor aria-hidden=true href=#the-io-problem>#</a></h3><p>From there, we took a <em>very</em> high level overview of some geospatial workloads.
Each loads some data (which we assumed came from Blob Storage), computed some
result, and stored that result. For example, a cloud-free mosaic from some
Sentinel-2 imagery:</p><p><img loading=lazy src=https://ai4edatasetspublicassets.blob.core.windows.net/assets/notebook-output/tutorials-cloudless-mosaic-sentinel2.ipynb/9.png alt="Cloudless mosaic"></p><p>I&rsquo;m realizing now that I should have included a vector data example, perhaps
loading an Overture Maps geoparquet file and doing a geospatial join.</p><p>Anyway, the point was to introduce some high-level concepts that we can use to
identify workloads amenable to GPU acceleration. First, we looked at a workloads
through time, which differ in how I/O vs. compute intensive they are.</p><p>For example, an I/O-bound workload:</p><img src=/assets/cng-forum-2025-iobound.svg><p>Contrast that with a (mostly) CPU-bound workload:</p><img src=/assets/cng-forum-2025-compute.svg><p>Trying to GPU-accelerate the I/O-bound workload will only bring disappointment: even if you manage to speed up the compute portion, it&rsquo;s such a small portion of the overall runtime to not make a meaningful difference.</p><p>But GPU-accelerating the compute-bound workload, on the other hand, can lead to
to a nice speedup:</p><img src=/assets/cng-forum-2025-compute-optimized.svg><p>A few things are worth emphasizing:</p><ol><li>You need to profile your workload to understand where time is being spent.</li><li>You might be able to turn an I/O bound problem into a compute bound problem
by optimizing it (choosing a better file format, placing your compute next to
the storage, choosing a faster library for I/O, parallelization, etc.)</li><li>I&rsquo;m implying that &ldquo;I/O&rdquo; is just sitting around waiting on the network. In
reality, some of I/O will be spent doing &ldquo;compute&rdquo; things (like parsing and
decompressing bytes.) And those portions of I/O can be GPU accelerated.</li><li>I glossed over the &ldquo;memory barrier&rdquo; at this point in the talk, but returned
to it later. There are again libraries (like
<a href=https://docs.rapids.ai/api/kvikio/stable/>KvikIO</a>) that can help with this.</li></ol><h3 id=pipelining>Pipelining<a hidden class=anchor aria-hidden=true href=#pipelining>#</a></h3><p><em>Some</em> (most?) problems can be broken into smaller units of work and,
potentially, parallelized. By breaking the larger problem into smaller pieces,
we have the opportunity to optimize the throughput of our workload through pipelining.</p><p>Pipelining lets us overlap various parts of the workload that are using
different parts of the system. For example I/O, which is mostly exercising the
network, can be pipelined with computation, which is mostly exercising the GPU.
First, we look at some poor pipelining:</p><img src=/assets/cng-forum-2025-pipeline-bad.svg><p>The workload serially reads data, computes the result, and writes the output.
This is inefficient: when you&rsquo;re reading or writing data the GPU is idle
(indeed, the CPU is mostly idle too, since it&rsquo;s waiting for bytes to move over
the network). And when you&rsquo;re computing the result, the CPU (and network) are
idle. This manifests as low utilization of the GPU, CPU, and network.</p><p>This second image shows good pipelining:</p><img src=/assets/cng-forum-2025-pipeline-good.svg><p>We&rsquo;ve set up our program to read, compute, and write batches in parallel. We achieve high utilization of the GPU, CPU, and network.</p><p>This general concept can apply to CPU-only systems, especially multi-core
systems. But the pain of low resource utilization is more pronounced with GPUs,
which tend to be more expensive.</p><p>Now, this is a massively oversimplified example where the batches of work happen
to be nicely sized and the workload doesn&rsquo;t require an coordination across
batches. But, with effort, the technique can be applied to a wide range of
problems.</p><h3 id=memory-bandwidth>Memory Bandwidth<a hidden class=anchor aria-hidden=true href=#memory-bandwidth>#</a></h3><p>This section was pressed for time, but I really wanted to at least touch on one
of the first things you&rsquo;ll hit when doing data analysis on the GPU: moving data
from host to device memory is relatively slow.</p><p>In the talk, I mostly just emphasized the benefits of leaving data on the GPU.
The memory hierarchy diagram from the <a href=https://github.com/Dao-AILab/flash-attention>Flash
Attention</a> paper gave a nice
visual representation of the tradeoff between bandwidth and size the different
tiers give (I&rsquo;d briefly mentioned the SRAM tier during the demo, since our most
optimized version used SRAM).</p><p>But as I mentioned in the talk, <em>most</em> people won&rsquo;t be interacting with the memory
hierarchy beyond minimizing transfers between the host and device.</p><h2 id=reach-out>Reach Out<a hidden class=anchor aria-hidden=true href=#reach-out>#</a></h2><p>As I mentioned earlier my main goal attending the conference was to hear what
the missing pieces of the GPU-accelerated geospatial landscape are (and to catch
up with the wonderful members of this community). <a href=mailto:toaugspurger@nvidia.com>Reach
out</a> with any feedback you might have.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://tomaugspurger.net/>Tom's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><a rel=me href=https://mastodon.social/@TomAugspurger></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>