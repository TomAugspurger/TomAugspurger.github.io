<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Using Python to tackle the CPS (Part 3) | Tom's Blog</title><meta name=keywords content="pandas"><meta name=description content="In part 2 of this series, we set the stage to parse the data files themselves.
As a reminder, we have a dictionary that looks like
id length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files."><meta name=author content><link rel=canonical href=https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/><link crossorigin=anonymous href=/assets/css/stylesheet.3690c96d8a707265a16abd3b389bb33e4e3916869c3142cba43a3cfaaed4b5f9.css integrity="sha256-NpDJbYpwcmWhar07OJuzPk45FoacMULLpDo8+q7Utfk=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://tomaugspurger.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tomaugspurger.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tomaugspurger.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://tomaugspurger.github.io/apple-touch-icon.png><link rel=mask-icon href=https://tomaugspurger.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Using Python to tackle the CPS (Part 3)"><meta property="og:description" content="In part 2 of this series, we set the stage to parse the data files themselves.
As a reminder, we have a dictionary that looks like
id length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files."><meta property="og:type" content="article"><meta property="og:url" content="https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/"><meta property="article:section" content="posts"><meta name=twitter:card content="summary"><meta name=twitter:title content="Using Python to tackle the CPS (Part 3)"><meta name=twitter:description content="In part 2 of this series, we set the stage to parse the data files themselves.
As a reminder, we have a dictionary that looks like
id length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://tomaugspurger.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Using Python to tackle the CPS (Part 3)","item":"https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Using Python to tackle the CPS (Part 3)","name":"Using Python to tackle the CPS (Part 3)","description":"In part 2 of this series, we set the stage to parse the data files themselves.\nAs a reminder, we have a dictionary that looks like\nid length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files.","keywords":["pandas"],"articleBody":"In part 2 of this series, we set the stage to parse the data files themselves.\nAs a reminder, we have a dictionary that looks like\nid length start end 0 HRHHID 15 1 15 1 HRMONTH 2 16 17 2 HRYEAR4 4 18 21 3 HURESPLI 2 22 23 4 HUFINAL 3 24 26 ... ... ... ... giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files. After that we can (finally) get into analyzing the data. The old joke is that statisticians spend 80% of their time munging their data, and 20% of their time complaining about munging their data. So 4 posts about data cleaning seems reasonable.\nThe data files are stored in fixed width format (FWF), one of the least human friendly ways to store data. We want to get to an HDF5 file, which is extremely fast and convinent with pandas.\nHere’s the first line of the raw data:\nhead -n 1 /Volumes/HDD/Users/tom/DataStorage/CPS/monthly/cpsb9401 881605952390 2 286-1 2201-1 1 1 1-1 1 5-1-1-1 22436991 1 2 1 6 194 2A61 -1 2 2-1-1-1-1 363 1-15240115 3-1 4 0 1-1 2 1-1660 1 2 2 2 6 236 2 8-1 0 1-1 1 1 1 2 1 2 57 57 57 1 0-1 2 5 3-1-1 2-1-1-1-1-1 2-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1 -1-1 169-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 2-1 0 4-1-1-1-1-1-1 -1-1-1 0 1 2-1-1-1-1-1-1-1-1-1 -1 -1-1-1 -1 -1-1-1 0-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 0-1-1-1-1-1 -1 -1 -1 0-1-1 0-1-1-1 -1 0-1-1-1-1-1-1-1-1 2-1-1-1-1 22436991 -1 0 22436991 22422317-1 0 0 0 1 0-1 050 0 0 0 011 0 0 0-1-1-1-1 0 0 0-1-1-1-1-1-1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1 1 1 1 1 1 1 1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1-1-1-1 We’ll use pandas’ read_fwf parser, passing in the widths we got from last post. One note of warning, the read_fwf function is slow. It’s written in plain python, and really makes you appreciate all the work Wes (the creater or pandas) put into making read_csv fast.\nStart by looking at the __main__ entry point. The basic idea is to call python make_hdf.py with an optional argument giving a file with a specific set of months you want to process. Otherwise, it processes every month in your data folder. There’s a bit of setup to make sure everything is order, and then we jump to the next important line:\nfor month in months: append_to_store(month, settings, skips, dds, start_time=start_time) I’d like to think that this function is fairly straightforward. We generate the names I use internally (name), read in the data dictionary that we parsed last time (dd and widths), and get to work reading the actual data with\ndf = pd.read_fwf(name + '.gz', widths=widths, names=dd.id.values, compression='gzip') Rather than stepping through every part of the processing (checking types, making sure indexes are unique, handling missing values, etc.) I want to focus on one specific issue: handling special cases. Since the CPS data aren’t consistent month to month, I needed a way transform the data for certain months differently that for others. The design I came up with worked pretty well.\nThe solution is in special_by_dd. Basically, each data dictionary (which describes the data layout for a month) has its own little quirks. For example, the data dictionary starting in January 1989 spread the two digits for age across two fields. The fix itself is extremely simple: df[\"PRTAGE\"] = df[\"AdAGEDG1\"] * 10 + df[\"AdAGEDG2\"], but knowing when to apply this fix, and how to apply several of these fixes is the interesting part.\nIn special_by_dd, I created a handful of closures (basically just functions inside other functions), and a dictionary mapping names to those functions.\nfunc_dict = {\"expand_year\": expand_year, \"combine_age\": combine_age, \"expand_hours\": expand_hours, \"align_lfsr\": align_lfsr, \"combine_hours\": combine_hours} Each one of these functions takes a DataFrame and returns a DataFrame, with the fix applied. The example above is combine_age. In a settings file, I had a JSON object mapping the data dictionary name to special functions to apply. For example, January 1989’s special case list was:\n\"jan1989\": [\"expand_year\", \"combine_age\", \"align_lfsr\", \"expand_hours\", \"combine_hours\"] I get the necessary special case functions and apply each with\nspecials = special_by_dd(settings[\"special_by_dd\"][dd_name]) for func in specials: df = specials[func](df, dd_name) specials is just func_dict from above, but filtered to be only the functions specified in the settings file. We select the function from the dictionary with specials[func] and then directly call it with (df, dd_name). Since functions are objects in python, we’re able to store them in dictionaries and pass them around like just about anything else.\nThis method gave a lot of flexibility. When I discovered a new way that one month’s layout differed from what I wanted, I simply wrote a function to handle the special case, added it to func_dict, and added the new special case to that month’s speical case list.\nThere’s a bit more standardization and other boring stuff that gets us to a good place: each month with the same layout. Now we get get to the tricky alignment, which I’ll save for another post.\n","wordCount":"849","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tomaugspurger.github.io/posts/tackling-the-cps-part-3/"},"publisher":{"@type":"Organization","name":"Tom's Blog","logo":{"@type":"ImageObject","url":"https://tomaugspurger.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tomaugspurger.github.io accesskey=h title="Tom's Blog (Alt + H)">Tom's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://tomaugspurger.github.io/about/ title=About><span>About</span></a></li><li><a href=https://tomaugspurger.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://tomaugspurger.github.io/index.xml title=RSS><span>RSS</span></a></li><li><a href=https://tomaugspurger.github.io/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Using Python to tackle the CPS (Part 3)</h1><div class=post-meta></div></header><div class=post-content><p>In <a href=http://tomaugspurger.github.io/blog/2014/02/04/tackling%20the%20cps%20(part%202)/>part 2</a> of this series, we set the stage to parse the data files themselves.</p><p>As a reminder, we have a dictionary that looks like</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span>         id  length  start  end
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>    HRHHID      <span style=color:#ae81ff>15</span>      <span style=color:#ae81ff>1</span>   <span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>   HRMONTH       <span style=color:#ae81ff>2</span>     <span style=color:#ae81ff>16</span>   <span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>   HRYEAR4       <span style=color:#ae81ff>4</span>     <span style=color:#ae81ff>18</span>   <span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>  HURESPLI       <span style=color:#ae81ff>2</span>     <span style=color:#ae81ff>22</span>   <span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>   HUFINAL       <span style=color:#ae81ff>3</span>     <span style=color:#ae81ff>24</span>   <span style=color:#ae81ff>26</span>
</span></span><span style=display:flex><span>         <span style=color:#f92672>...</span>     <span style=color:#f92672>...</span>    <span style=color:#f92672>...</span>  <span style=color:#f92672>...</span>
</span></span></code></pre></div><p>giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files. After that we can (finally) get into analyzing the data. The old joke is that statisticians spend 80% of their time munging their data, and 20% of their time complaining about munging their data. So 4 posts about data cleaning seems reasonable.</p><p>The data files are stored in fixed width format (FWF), one of the least human friendly ways to store data.
We want to get to an <a href=http://www.hdfgroup.org/HDF5/>HDF5</a> file, which is extremely fast and convinent with pandas.</p><p>Here&rsquo;s the first line of the raw data:</p><pre tabindex=0><code>head -n 1 /Volumes/HDD/Users/tom/DataStorage/CPS/monthly/cpsb9401
881605952390 2  286-1 2201-1 1 1 1-1 1 5-1-1-1  22436991 1 2 1 6 194 2A61 -1 2 2-1-1-1-1 363 1-15240115 3-1 4 0 1-1 2 1-1660 1 2 2 2 6 236 2 8-1 0 1-1 1 1 1 2 1 2 57 57 57 1 0-1 2 5 3-1-1 2-1-1-1-1-1 2-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1 -1-1  169-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 2-1 0 4-1-1-1-1-1-1 -1-1-1 0 1 2-1-1-1-1-1-1-1-1-1 -1 -1-1-1 -1 -1-1-1 0-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 0-1-1-1-1-1  -1  -1  -1  0-1-1      0-1-1-1      -1      0-1-1-1-1-1-1-1-1 2-1-1-1-1  22436991        -1         0  22436991  22422317-1         0 0 0 1 0-1 050 0 0 0 011 0 0 0-1-1-1-1 0 0 0-1-1-1-1-1-1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1 1 1 1 1 1 1 1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1-1-1-1
</code></pre><p>We&rsquo;ll use pandas&rsquo; <a href=http://pandas.pydata.org/pandas-docs/version/0.13.0/generated/pandas.io.parsers.read_fwf.html#pandas.io.parsers.read_fwf><code>read_fwf</code></a> parser, passing in the widths we got from last post.
One note of warning, the <code>read_fwf</code> function is slow. It&rsquo;s written in plain python, and really makes you appreciate <a href="http://wesmckinney.com/blog/?p=543">all the work</a> Wes (the creater or pandas) put into making <code>read_csv</code> fast.</p><p>Start by looking at the <code>__main__</code> <a href=https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L786>entry point</a>. The basic idea is to call <code>python make_hdf.py</code> with an optional argument giving a file with a specific set of months you want to process. Otherwise, it processes every month in your data folder. There&rsquo;s a bit of setup to make sure everything is order, and then we jump to the <a href=https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L813>next important line</a>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>for</span> month <span style=color:#f92672>in</span> months:
</span></span><span style=display:flex><span>    append_to_store(month, settings, skips, dds, start_time<span style=color:#f92672>=</span>start_time)
</span></span></code></pre></div><p>I&rsquo;d like to think that <a href=https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L725>this function</a> is fairly straightforward. We generate the names I use internally (<code>name</code>), read in the data dictionary that we parsed last time (<code>dd</code> and <code>widths</code>), and get to work reading the actual data with</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_fwf(name <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;.gz&#39;</span>, widths<span style=color:#f92672>=</span>widths,
</span></span><span style=display:flex><span>                 names<span style=color:#f92672>=</span>dd<span style=color:#f92672>.</span>id<span style=color:#f92672>.</span>values, compression<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gzip&#39;</span>)
</span></span></code></pre></div><p>Rather than stepping through every part of the processing (checking types, making sure indexes are unique, handling missing values, etc.) I want to focus on one specific issue: handling special cases. Since the CPS data aren&rsquo;t consistent month to month, I needed a way transform the data for certain months differently that for others. The design I came up with worked pretty well.</p><p>The solution is in <a href=https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L603><code>special_by_dd</code></a>. Basically, each data dictionary (which describes the data layout for a month) has its own little quirks.
For example, the data dictionary starting in January 1989 spread the two digits for age across two fields. The fix itself is extremely simple: <code>df["PRTAGE"] = df["AdAGEDG1"] * 10 + df["AdAGEDG2"]</code>, but knowing when to apply this fix, and how to apply several of these fixes is the interesting part.</p><p>In <a href=https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L603><code>special_by_dd</code></a>, I created a handful of closures (basically just functions inside other functions), and a dictionary mapping names to those functions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>func_dict <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;expand_year&#34;</span>: expand_year, <span style=color:#e6db74>&#34;combine_age&#34;</span>: combine_age,
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#34;expand_hours&#34;</span>: expand_hours, <span style=color:#e6db74>&#34;align_lfsr&#34;</span>: align_lfsr,
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#34;combine_hours&#34;</span>: combine_hours}
</span></span></code></pre></div><p>Each one of these functions takes a DataFrame and returns a DataFrame, with the fix applied. The example above is <code>combine_age</code>.
In a settings file, I had a JSON object mapping the data dictionary name to special functions to apply. For example, January 1989&rsquo;s special case list was:</p><pre tabindex=0><code>&#34;jan1989&#34;: [&#34;expand_year&#34;, &#34;combine_age&#34;, &#34;align_lfsr&#34;, &#34;expand_hours&#34;, &#34;combine_hours&#34;]
</code></pre><p>I get the necessary special case functions and apply each with</p><pre tabindex=0><code>specials = special_by_dd(settings[&#34;special_by_dd&#34;][dd_name])
for func in specials:
    df = specials[func](df, dd_name)
</code></pre><p><code>specials</code> is just <code>func_dict</code> from above, but filtered to be only the functions specified in the settings file.
We select the function from the dictionary with <code>specials[func]</code> and then directly call it with <code>(df, dd_name)</code>.
Since functions are objects in python, we&rsquo;re able to store them in dictionaries and pass them around like just about anything else.</p><p>This method gave a lot of flexibility. When I discovered a new way that one month&rsquo;s layout differed from what I wanted, I simply wrote a function to handle the special case, added it to <code>func_dict</code>, and added the new special case to that month&rsquo;s speical case list.</p><p>There&rsquo;s a bit more standardization and other boring stuff that gets us to a good place: each month with the same layout. Now we get get to the tricky alignment, which I&rsquo;ll save for another post.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://tomaugspurger.github.io/tags/pandas/>pandas</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://tomaugspurger.github.io>Tom's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><a rel=me href=https://mastodon.social/@TomAugspurger></a>
<script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>