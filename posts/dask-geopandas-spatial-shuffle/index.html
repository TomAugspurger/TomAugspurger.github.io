<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Dask Geopandas Spatial Shuffle | Tom's Blog</title>
<meta name=keywords content><meta name=description content="Over at https://github.com/opengeospatial/geoparquet/discussions/251, we&rsquo;re
having a nice discussion about how best to partition geoparquet files for
serving over object storage. Thanks to geoparquet&rsquo;s design, just being an
extension of parquet, it immediately benefits from all the wisdom around how
best to partition plain parquet datasets. The only additional wrinkle for
geoparquet is, unsurprisingly, the geo component.
It&rsquo;s pretty common for users to read all the features in a small spatial area (a
city, say) so optimizing for that use case is a good default. Simplifying a bit,
reading small spatial subsets of a larger dataset will be fastest if all the
features that are geographically close together are also &ldquo;close&rdquo; together in the
parquet dataset, and each part of the parquet dataset only contains data that&rsquo;s
physically close together. That gives you the data you want in the fewest number
of file reads / HTTP requests, and minimizes the amount of &ldquo;wasted&rdquo; reads (data
that&rsquo;s read, only to be immediately discarded because it&rsquo;s outside your area of
interest)."><meta name=author content><link rel=canonical href=https://tomaugspurger.net/posts/dask-geopandas-spatial-shuffle/><link crossorigin=anonymous href=/assets/css/stylesheet.ced21e6d3497ee93fed8f8b357448095840179bd510b5ea0e6013078712e6dd1.css integrity="sha256-ztIebTSX7pP+2PizV0SAlYQBeb1RC16g5gEweHEubdE=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://tomaugspurger.net/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://tomaugspurger.net/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://tomaugspurger.net/favicon-32x32.png><link rel=apple-touch-icon href=https://tomaugspurger.net/apple-touch-icon.png><link rel=mask-icon href=https://tomaugspurger.net/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://tomaugspurger.net/posts/dask-geopandas-spatial-shuffle/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Dask Geopandas Spatial Shuffle"><meta property="og:description" content="Over at https://github.com/opengeospatial/geoparquet/discussions/251, we&rsquo;re
having a nice discussion about how best to partition geoparquet files for
serving over object storage. Thanks to geoparquet&rsquo;s design, just being an
extension of parquet, it immediately benefits from all the wisdom around how
best to partition plain parquet datasets. The only additional wrinkle for
geoparquet is, unsurprisingly, the geo component.
It&rsquo;s pretty common for users to read all the features in a small spatial area (a
city, say) so optimizing for that use case is a good default. Simplifying a bit,
reading small spatial subsets of a larger dataset will be fastest if all the
features that are geographically close together are also &ldquo;close&rdquo; together in the
parquet dataset, and each part of the parquet dataset only contains data that&rsquo;s
physically close together. That gives you the data you want in the fewest number
of file reads / HTTP requests, and minimizes the amount of &ldquo;wasted&rdquo; reads (data
that&rsquo;s read, only to be immediately discarded because it&rsquo;s outside your area of
interest)."><meta property="og:type" content="article"><meta property="og:url" content="https://tomaugspurger.net/posts/dask-geopandas-spatial-shuffle/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-18T10:33:34-06:00"><meta property="article:modified_time" content="2024-12-18T10:33:34-06:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Dask Geopandas Spatial Shuffle"><meta name=twitter:description content="Over at https://github.com/opengeospatial/geoparquet/discussions/251, we&rsquo;re
having a nice discussion about how best to partition geoparquet files for
serving over object storage. Thanks to geoparquet&rsquo;s design, just being an
extension of parquet, it immediately benefits from all the wisdom around how
best to partition plain parquet datasets. The only additional wrinkle for
geoparquet is, unsurprisingly, the geo component.
It&rsquo;s pretty common for users to read all the features in a small spatial area (a
city, say) so optimizing for that use case is a good default. Simplifying a bit,
reading small spatial subsets of a larger dataset will be fastest if all the
features that are geographically close together are also &ldquo;close&rdquo; together in the
parquet dataset, and each part of the parquet dataset only contains data that&rsquo;s
physically close together. That gives you the data you want in the fewest number
of file reads / HTTP requests, and minimizes the amount of &ldquo;wasted&rdquo; reads (data
that&rsquo;s read, only to be immediately discarded because it&rsquo;s outside your area of
interest)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tomaugspurger.net/posts/"},{"@type":"ListItem","position":2,"name":"Dask Geopandas Spatial Shuffle","item":"https://tomaugspurger.net/posts/dask-geopandas-spatial-shuffle/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Dask Geopandas Spatial Shuffle","name":"Dask Geopandas Spatial Shuffle","description":"Over at https://github.com/opengeospatial/geoparquet/discussions/251, we\u0026rsquo;re having a nice discussion about how best to partition geoparquet files for serving over object storage. Thanks to geoparquet\u0026rsquo;s design, just being an extension of parquet, it immediately benefits from all the wisdom around how best to partition plain parquet datasets. The only additional wrinkle for geoparquet is, unsurprisingly, the geo component.\nIt\u0026rsquo;s pretty common for users to read all the features in a small spatial area (a city, say) so optimizing for that use case is a good default. Simplifying a bit, reading small spatial subsets of a larger dataset will be fastest if all the features that are geographically close together are also \u0026ldquo;close\u0026rdquo; together in the parquet dataset, and each part of the parquet dataset only contains data that\u0026rsquo;s physically close together. That gives you the data you want in the fewest number of file reads / HTTP requests, and minimizes the amount of \u0026ldquo;wasted\u0026rdquo; reads (data that\u0026rsquo;s read, only to be immediately discarded because it\u0026rsquo;s outside your area of interest).\n","keywords":[],"articleBody":"Over at https://github.com/opengeospatial/geoparquet/discussions/251, we’re having a nice discussion about how best to partition geoparquet files for serving over object storage. Thanks to geoparquet’s design, just being an extension of parquet, it immediately benefits from all the wisdom around how best to partition plain parquet datasets. The only additional wrinkle for geoparquet is, unsurprisingly, the geo component.\nIt’s pretty common for users to read all the features in a small spatial area (a city, say) so optimizing for that use case is a good default. Simplifying a bit, reading small spatial subsets of a larger dataset will be fastest if all the features that are geographically close together are also “close” together in the parquet dataset, and each part of the parquet dataset only contains data that’s physically close together. That gives you the data you want in the fewest number of file reads / HTTP requests, and minimizes the amount of “wasted” reads (data that’s read, only to be immediately discarded because it’s outside your area of interest).\nParquet datasets have two levels of nesting we can use to achieve our goal:\nParquet files within a dataset Row groups within each parquet file And (simplifying over some details again) we choose the number row groups and files so that stuff fits in memory when we actually read some data, while avoiding too many individual files to deal with.\nSo, given some table of geometries, we want to repartition (AKA shuffle) the records so that all the ones that are close in space are also close in the table. This process is called “spatial partitioning” or “spatial shuffling”.\nSpatial Partitioning Dewey Dunnington put together a nice post on various ways of doing this spatial partitioning on a real-world dataset using DuckDB. This post will show how something similar can be done with dask-geopandas.\nPrep the data A previous post from Dewy shows how to get the data. Once you’ve downloaded and unzipped the Flatgeobuf file, you can convert it to geoparquet with dask-geopandas.\nThe focus today is on repartitioning, not converting between file formats, so let’s just quickly convert that Flatgeobuf to geoparquet.\nroot = pathlib.Path(\"data\") info = pyogrio.read_info(root / \"microsoft-buildings-point.fgb\") split = root / \"microsoft-buildings-point-split.parquet\" n_features = info[\"features\"] CHUNK_SIZE=1_000_000 print(n_features // CHUNK_SIZE + 1) chunks = dask.array.core.normalize_chunks((CHUNK_SIZE,), shape=(n_features,)) slices = [x[0] for x in dask.array.core.slices_from_chunks(chunks)] def read_part(rows): return geopandas.read_file(\"data/microsoft-buildings-point.fgb\", rows=rows)[[\"geometry\"]] df = dask.dataframe.from_map(read_part, slices) shutil.rmtree(split, ignore_errors=True) df.to_parquet(split, compression=\"zstd\") Spatial Partitioning with dask-geopandas Now we can do the spatial partitioning with dask-geopandas. The dask-geopandas user guide includes a nice overview of the background and different options available. But the basic version is to use the spatial_shuffle method, which computes some good “divisions” of the data and rearranges the table to be sorted by those.\ndf = dask_geopandas.read_parquet(split) %time shuffled = df.spatial_shuffle(by=\"hilbert\") %time shuffled.to_parquet(\"data/hilbert-16.parquet\", compression=\"zstd\") On my local machine (iMac with a 8 CPU cores (16 hyper-threaded) and 40 GB of RAM), discovering the partitions took about 3min 40s. Rewriting the data to be shuffled took about 3min 25s. Recent versions of Dask include some nice stability and performance improvements, led by the folks at Coiled, which made this run without issue. I ran this locally, but it would be even faster (and scale to much larger datasets) with a cluster of machines and object-storage.\nNow that they’re shuffled, we can plot the resulting spatial partitions:\nr = dask_geopandas.read_parquet(\"data/hilbert-16.parquet\") ax = r.spatial_partitions.plot(edgecolor=\"black\", cmap=\"tab20\", alpha=0.25, figsize=(12, 9)) ax.set_axis_off() ax.set(title=\"Hilbert partitioning (level=16)\") The outline of the United States is visible, and the spatial partitions do a good (but not perfect) job of making mostly non-overlapping, spatially compact partitions.\nwhich gives\nHere’s a similar plot for by=\"geohash\"\nAnd for by=\"morton\"\nEach partition ends up with approximately 1,000,000 rows (our original chunk size). Here’s a histogram of the count per partition:\nimport seaborn as sns counts = [fragment.count_rows() for fragment in pyarrow.parquet.ParquetDataset(\"data/hilbert-16.parquet/\").fragments] sns.displot(counts); The discussion also mentions KD trees as potentially better way of doing the partitioning. I’ll look into that and will follow up if anything comes out of it.\n","wordCount":"665","inLanguage":"en","datePublished":"2024-12-18T10:33:34-06:00","dateModified":"2024-12-18T10:33:34-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tomaugspurger.net/posts/dask-geopandas-spatial-shuffle/"},"publisher":{"@type":"Organization","name":"Tom's Blog","logo":{"@type":"ImageObject","url":"https://tomaugspurger.net/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tomaugspurger.net/ accesskey=h title="Tom's Blog (Alt + H)">Tom's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://tomaugspurger.net/about/ title=About><span>About</span></a></li><li><a href=https://tomaugspurger.net/archives title=Archive><span>Archive</span></a></li><li><a href=https://tomaugspurger.net/index.xml title=RSS><span>RSS</span></a></li><li><a href=https://tomaugspurger.net/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Dask Geopandas Spatial Shuffle</h1><div class=post-meta><span title='2024-12-18 10:33:34 -0600 -0600'>December 18, 2024</span></div></header><div class=post-content><p>Over at <a href=https://github.com/opengeospatial/geoparquet/discussions/251>https://github.com/opengeospatial/geoparquet/discussions/251</a>, we&rsquo;re
having a nice discussion about how best to partition geoparquet files for
serving over object storage. Thanks to geoparquet&rsquo;s design, just being an
extension of parquet, it immediately benefits from all the wisdom around how
best to partition plain parquet datasets. The only additional wrinkle for
geoparquet is, unsurprisingly, the geo component.</p><p>It&rsquo;s pretty common for users to read all the features in a small spatial area (a
city, say) so optimizing for that use case is a good default. Simplifying a bit,
reading small spatial subsets of a larger dataset will be fastest if all the
features that are geographically close together are also &ldquo;close&rdquo; together in the
parquet dataset, and each part of the parquet dataset only contains data that&rsquo;s
physically close together. That gives you the data you want in the fewest number
of file reads / HTTP requests, and minimizes the amount of &ldquo;wasted&rdquo; reads (data
that&rsquo;s read, only to be immediately discarded because it&rsquo;s outside your area of
interest).</p><p>Parquet datasets have two levels of nesting we can use to achieve our goal:</p><ol><li>Parquet files within a dataset</li><li>Row groups within each parquet file</li></ol><p>And (simplifying over some details again) we choose the number row groups and
files so that stuff fits in memory when we actually read some data, while
avoiding <em>too</em> many individual files to deal with.</p><p>So, given some table of geometries, we want to repartition (AKA shuffle) the
records so that all the ones that are close in space are also close in the
table. This process is called &ldquo;spatial partitioning&rdquo; or &ldquo;spatial shuffling&rdquo;.</p><h2 id=spatial-partitioning>Spatial Partitioning<a hidden class=anchor aria-hidden=true href=#spatial-partitioning>#</a></h2><p><a href=https://dewey.dunnington.ca/#about>Dewey Dunnington</a> put together a <a href=https://dewey.dunnington.ca/post/2024/partitioning-strategies-for-bigger-than-memory-spatial-data/>nice
post</a>
on various ways of doing this spatial partitioning on a real-world dataset using
DuckDB. This post will show how something similar can be done with
dask-geopandas.</p><h3 id=prep-the-data>Prep the data<a hidden class=anchor aria-hidden=true href=#prep-the-data>#</a></h3><p>A <a href=https://dewey.dunnington.ca/post/2024/wrangling-and-joining-130m-points-with-duckdb--the-open-source-spatial-stack/>previous
post</a>
from Dewy shows how to get the data. Once you&rsquo;ve downloaded and unzipped the
Flatgeobuf file, you can convert it to geoparquet with dask-geopandas.</p><p>The focus today is on repartitioning, not converting between file formats,
so let&rsquo;s just quickly convert that Flatgeobuf to geoparquet.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>root <span style=color:#f92672>=</span> pathlib<span style=color:#f92672>.</span>Path(<span style=color:#e6db74>&#34;data&#34;</span>)
</span></span><span style=display:flex><span>info <span style=color:#f92672>=</span> pyogrio<span style=color:#f92672>.</span>read_info(root <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;microsoft-buildings-point.fgb&#34;</span>)
</span></span><span style=display:flex><span>split <span style=color:#f92672>=</span> root <span style=color:#f92672>/</span> <span style=color:#e6db74>&#34;microsoft-buildings-point-split.parquet&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>n_features <span style=color:#f92672>=</span> info[<span style=color:#e6db74>&#34;features&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>CHUNK_SIZE<span style=color:#f92672>=</span><span style=color:#ae81ff>1_000_000</span>
</span></span><span style=display:flex><span>print(n_features <span style=color:#f92672>//</span> CHUNK_SIZE <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chunks <span style=color:#f92672>=</span> dask<span style=color:#f92672>.</span>array<span style=color:#f92672>.</span>core<span style=color:#f92672>.</span>normalize_chunks((CHUNK_SIZE,), shape<span style=color:#f92672>=</span>(n_features,))
</span></span><span style=display:flex><span>slices <span style=color:#f92672>=</span> [x[<span style=color:#ae81ff>0</span>] <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> dask<span style=color:#f92672>.</span>array<span style=color:#f92672>.</span>core<span style=color:#f92672>.</span>slices_from_chunks(chunks)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_part</span>(rows):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> geopandas<span style=color:#f92672>.</span>read_file(<span style=color:#e6db74>&#34;data/microsoft-buildings-point.fgb&#34;</span>, rows<span style=color:#f92672>=</span>rows)[[<span style=color:#e6db74>&#34;geometry&#34;</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> dask<span style=color:#f92672>.</span>dataframe<span style=color:#f92672>.</span>from_map(read_part, slices)
</span></span><span style=display:flex><span>shutil<span style=color:#f92672>.</span>rmtree(split, ignore_errors<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>to_parquet(split, compression<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;zstd&#34;</span>)
</span></span></code></pre></div><h3 id=spatial-partitioning-with-dask-geopandas>Spatial Partitioning with dask-geopandas<a hidden class=anchor aria-hidden=true href=#spatial-partitioning-with-dask-geopandas>#</a></h3><p>Now we can do the spatial partitioning with dask-geopandas. The dask-geopandas
<a href=https://dask-geopandas.readthedocs.io/en/stable/guide/spatial-partitioning.html>user
guide</a>
includes a nice overview of the background and different options available. But
the basic version is to use the <code>spatial_shuffle</code> method, which computes some
good &ldquo;divisions&rdquo; of the data and rearranges the table to be sorted by those.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> dask_geopandas<span style=color:#f92672>.</span>read_parquet(split)
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>time shuffled <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>spatial_shuffle(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hilbert&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>time shuffled<span style=color:#f92672>.</span>to_parquet(<span style=color:#e6db74>&#34;data/hilbert-16.parquet&#34;</span>, compression<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;zstd&#34;</span>)
</span></span></code></pre></div><p>On my local machine (iMac with a 8 CPU cores (16 hyper-threaded) and 40 GB of RAM), discovering the partitions took about 3min 40s.
Rewriting the data to be shuffled took about 3min 25s. Recent versions of Dask include some nice <a href=https://docs.coiled.io/blog/shuffling-large-data-at-constant-memory.html>stability</a> and <a href=https://docs.coiled.io/blog/dask-dataframe-is-fast.html>performance</a> improvements, led by the folks at Coiled, which made this run without issue. I ran this locally, but it would be even faster (and scale to much larger datasets) with a cluster of machines and object-storage.</p><p>Now that they&rsquo;re shuffled, we can plot the resulting spatial partitions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>r <span style=color:#f92672>=</span> dask_geopandas<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;data/hilbert-16.parquet&#34;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> r<span style=color:#f92672>.</span>spatial_partitions<span style=color:#f92672>.</span>plot(edgecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;black&#34;</span>, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;tab20&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.25</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>9</span>))
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_axis_off()
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set(title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Hilbert partitioning (level=16)&#34;</span>)
</span></span></code></pre></div><p>The outline of the United States is visible, and the spatial partitions do a good (but not perfect) job of making mostly non-overlapping, spatially compact partitions.</p><p>which gives</p><p><img loading=lazy src=/images/hilbert-16.png alt="Hilbert partitioning"></p><p>Here&rsquo;s a similar plot for <code>by="geohash"</code></p><p><img loading=lazy src=/images/geohash.png alt="Geohash partitioning"></p><p>And for <code>by="morton"</code></p><p><img loading=lazy src=/images/morton-16.png alt="Morton partitioning"></p><p>Each partition ends up with approximately 1,000,000 rows (our original chunk size). Here&rsquo;s a histogram of the count per partition:</p><pre tabindex=0><code>import seaborn as sns
counts = [fragment.count_rows() for fragment in pyarrow.parquet.ParquetDataset(&#34;data/hilbert-16.parquet/&#34;).fragments]

sns.displot(counts);
</code></pre><p><img loading=lazy src=/images/counts-per-partition.png alt="Count per partition"></p><p>The <a href=https://github.com/opengeospatial/geoparquet/discussions/251>discussion</a> also mentions KD trees as potentially better way of doing the partitioning. I&rsquo;ll look into that and will follow up if anything comes out of it.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://tomaugspurger.net/>Tom's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><a rel=me href=https://mastodon.social/@TomAugspurger></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>