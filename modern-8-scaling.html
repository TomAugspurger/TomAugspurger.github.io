<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="/theme/css/style.less">
  <script src="//cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="icon" type="image/vnd.microsoft.icon" href="/">
  <link rel="stylesheet" type="text/css" href="/theme/css/normalize.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Roboto+Mono">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/hatena-bookmark-icon.css">
  <link rel="stylesheet" type="text/css" href="theme/css/custom.css">


  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Tom Augspurger">
  <meta name="description" content="Posts and writings by Tom Augspurger">

  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="datas-frame Atom" />

<meta name="keywords" content="pandas">

  <title>
    datas-frame
&ndash; Modern Pandas (Part 8): Scaling  </title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48304175-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
  <main>
    <header>
      <div class="site-name">
        <a href="">datas-frame</a>
      </div>
      <p>
        <a href="/archives.html"><i class="fa fa-archive"></i> Archive</a>
      </p>
    </header>

<article>
  <div class="article__title">
    <h1><a href="/modern-8-scaling.html">Modern Pandas (Part 8): Scaling</a></h1>
  </div>
  <div class="article__meta">
    <p class="article__meta__post-date">Posted on: Mon 23 April 2018</p>
 Tags:
      <a href="/tag/pandas.html">#pandas</a>    </p>
  </div>
  <div class="article__text">
    <hr>
<p>This is part 1 in my series on writing modern idiomatic pandas.</p>
<ul>
<li><a href="modern-1-intro">Modern Pandas</a></li>
<li><a href="method-chaining">Method Chaining</a></li>
<li><a href="modern-3-indexes">Indexes</a></li>
<li><a href="modern-4-performance">Fast Pandas</a></li>
<li><a href="modern-5-tidy">Tidy Data</a></li>
<li><a href="modern-6-visualization">Visualization</a></li>
<li><a href="modern-7-timeseries">Time Series</a></li>
<li><a href="modern-8-scaling">Scaling</a></li>
</ul>
<hr>
<p>As I sit down to write this, the third-most popular pandas question on StackOverflow covers <a href="https://stackoverflow.com/q/14262433/1889400">how to use pandas for large datasets</a>. This is in tension with the fact that a pandas DataFrame is an in memory container. <em>You can't have a <code>DataFrame</code> larger than your machine's RAM</em>. In practice, your available RAM should be several times the size of your dataset, as you or pandas will have to make intermediate copies as part of the analysis.</p>
<p>Historically, pandas users have scaled to larger datasets by switching away from pandas or using iteration. Both of these are perfectly valid approaches, but changing your workflow in response to scaling data is unfortunate. I use pandas because it's a pleasant experience, and I would like that experience to scale to larger datasets. That's what <a href="dask.pydata.org/">Dask</a>, a parallel computing library, enables. We'll discuss Dask in detail later. But first, let's work through scaling a simple analysis to a larger than memory dataset.</p>
<p>Our task is to find the 100 most-common occupations reported in the FEC's <a href="https://classic.fec.gov/finance/disclosure/ftpdet.shtml">individual contributions dataest</a>. The files are split by election cycle (2007-2008, 2009-2010, ...). You can find some scripts for downloading the data in <a href="https://github.com/tomaugspurger/scalable-ml-fec">this repository</a>. My laptop can read in each cycle's file individually, but the full dataset is too large to read in at once. Let's read in just 2010's file, and do the "small data" version.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s2">&quot;data/indiv-10.parq&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;occupation&#39;</span><span class="p">],</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;pyarrow&#39;</span><span class="p">)</span>

<span class="n">most_common</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">most_common</span>
</pre></div>


<div class="output highlight">
<pre>
    RETIRED                    279775
    ATTORNEY                   166768
    PRESIDENT                   81336
    PHYSICIAN                   73015
    HOMEMAKER                   66057
                                ...  
    C.E.O.                       1945
    EMERGENCY PHYSICIAN          1944
    BUSINESS EXECUTIVE           1924
    BUSINESS REPRESENTATIVE      1879
    GOVERNMENT AFFAIRS           1867
    Name: occupation, Length: 100, dtype: int64
    </pre>
</div>

<p>After reading in the file, our actual analysis is a simple 1-liner using two operations built into pandas. Truly, the best of all possible worlds.</p>
<p>Next, we'll do the analysis for the entire dataset, which is larger than memory, in two ways. First we'll use just pandas and iteration. Then we'll use Dask.</p>
<h3>Using Iteration</h3>
<p>To do this with just pandas we have to rewrite our code, taking care to never have too much data in RAM at once. We will</p>
<ol>
<li>Create a global <code>total_counts</code> Series that contains the counts from all of the files processed so far</li>
<li>Read in a file</li>
<li>Compute a temporary variable <code>counts</code> with the counts for just this file</li>
<li>Add that temporary <code>counts</code> into the global <code>total_counts</code></li>
<li>Select the 100 largest with <code>.nlargest</code></li>
</ol>
<p>This works since the <code>total_counts</code> Series is relatively small, and each year's data fits in RAM individually. Our peak memory usage should be the size of the largest individual cycle (2015-2016) plus the size of <code>total_counts</code> (which we can essentially ignore).</p>
<div class="highlight"><pre><span></span><span class="n">files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;indiv-*.parq&quot;</span><span class="p">))</span>

<span class="n">total_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">()</span>

<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;occupation&#39;</span><span class="p">],</span>
                         <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
    <span class="n">total_counts</span> <span class="o">=</span> <span class="n">total_counts</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">total_counts</span> <span class="o">=</span> <span class="n">total_counts</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<div class="output highlight">
<pre>
RETIRED                    4769520
NOT EMPLOYED               2656988
ATTORNEY                   1340434
PHYSICIAN                   659082
HOMEMAKER                   494187
                            ...   
CHIEF EXECUTIVE OFFICER      26551
SURGEON                      25521
EDITOR                       25457
OPERATOR                     25151
ORTHOPAEDIC SURGEON          24384
Name: occupation, Length: 100, dtype: int64
</pre>
</div>

<p>While this works, our small one-liner has ballooned in size (and complexity; should you <em>really</em> have to know about <code>Series.add</code>'s <code>fill_value</code> parameter for this simple analysis?). If only there was a better way...</p>
<h3>Using Dask</h3>
<p>With Dask, we essentially recover our original code. We'll change our import to use <code>dask.dataframe.read_parquet</code>, which returns a Dask DataFrame.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="kn">as</span> <span class="nn">dd</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s2">&quot;data/indiv-*.parquet&quot;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;pyarrow&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;occupation&#39;</span><span class="p">])</span>

<span class="n">most_common</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">most_common</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<div class="output highlight">
<pre>
RETIRED                    4769520
NOT EMPLOYED               2656988
ATTORNEY                   1340434
PHYSICIAN                   659082
HOMEMAKER                   494187
                            ...   
CHIEF EXECUTIVE OFFICER      26551
SURGEON                      25521
EDITOR                       25457
OPERATOR                     25151
ORTHOPAEDIC SURGEON          24384
Name: occupation, Length: 100, dtype: int64
</pre>
</div>

<p>There are a couple differences from the original pandas version, which we'll discuss next, but overall I hope you agree that the Dask version is nicer than the version using iteration.</p>
<h2>Dask</h2>
<p>Now that we've seen <code>dask.dataframe</code> in action, let's step back and discuss Dask a bit. Dask is an open-source project that natively parallizes Python. I'm a happy user of and contributor to Dask.</p>
<p>At a high-level, Dask provides familiar APIs for <a href="https://dask.pydata.org/en/latest/array.html">large N-dimensional arrays</a>, <a href="https://dask.pydata.org/en/latest/dataframe.html">large DataFrames</a>, and <a href="https://distributed.readthedocs.io/en/latest/quickstart.html#map-and-submit-functions">familiar</a> ways to parallelize <a href="https://dask.pydata.org/en/latest/delayed.html">custom algorithms</a>.</p>
<p>At a low-level, each of these is built on high-performance <a href="http://dask.pydata.org/en/latest/scheduling.html">task scheduling</a> that executes operations in parallel. The <a href="http://dask.pydata.org/en/latest/spec.html">low-level details</a> aren't too important; all we care about is that</p>
<ol>
<li>Dask works with <em>task graphs</em> (<em>tasks</em>: functions to call on data, and <em>graphs</em>: the relationships between tasks).</li>
<li>This is a flexible and performant way to parallelize many different kinds of problems.</li>
</ol>
<p>To understand point 1, let's examine the difference between a Dask DataFrame and a pandas DataFrame. When we read in <code>df</code> with <code>dd.read_parquet</code>, we received a Dask DataFrame.</p>
<div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>


<div class="output">
<div><strong>Dask DataFrame Structure:</strong></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>occupation</th>
    </tr>
    <tr>
      <th>npartitions=35</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>object</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>
<div>Dask Name: read-parquet, 35 tasks</div>
</div>

<p>A Dask DataFrame consists of many pandas DataFrames arranged by the index. Dask is really just coordinating these pandas DataFrames.</p>
<p><img src="http://dask.pydata.org/en/latest/_images/dask-dataframe.svg" width="50%"/></p>
<p>All the actual computation (reading from disk, computing the value counts, etc.) eventually use pandas internally. If I do <code>df.occupation.str.len</code>, Dask will coordinate calling <code>pandas.Series.str.len</code> on each of the pandas DataFrames.</p>
<p>Those reading carefully will notice a problem with the statement "A Dask DataFrame consists of many pandas DataFrames". Our initial problem was that we didn't have enough memory for those DataFrames! How can Dask be coordinating DataFrames if there isn't enough memory? This brings us to the second major difference: Dask DataFrames (and arrays) are lazy. Operations on them don't execute and produce the final result immediately. Rather, calling methods on them builds up a task graph.</p>
<p>We can visualize task graphs using <code>graphviz</code>. For the blog, I've trimmed down the example to be a subset of the entire graph.</p>
<div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;LR&#39;</span><span class="p">)</span>
</pre></div>


<div class="output"><img src="images/scalable-read-simple.svg"></div>

<p><code>df</code> (the dask DataFrame consisting of many pandas DataFrames) has a task graph with 5 calls to a parquet reader (one for each file), each of which produces a DataFrame when called.</p>
<p>Calling additional methods on <code>df</code> adds additional tasks to this graph. For example, our <code>most_common</code> Series has three additional calls</p>
<ul>
<li>Select the <code>occupation</code> column (<code>__getitem__</code>)</li>
<li>Perform the value counts</li>
<li>Select the 100 largest values</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">most_common</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">most_common</span>
</pre></div>


<div class="output highlight">
<pre>

    Dask Series Structure:
    npartitions=1
        int64
          ...
    Name: occupation, dtype: int64
    Dask Name: series-nlargest-agg, 113 tasks
</pre>
</div>

<p>Which we can visualize.</p>
<div class="highlight"><pre><span></span><span class="n">most_common</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;LR&#39;</span><span class="p">)</span>
</pre></div>


<div class="output"><img src="images/scalable-most-common.svg"></div>

<p>So <code>most_common</code> doesn't hold the actual answer yet. Instead, it holds a recipe for the answer; a list of all the steps to take to get the concrete result. One way to ask for the result is with the <code>compute</code> method.</p>
<div class="highlight"><pre><span></span><span class="n">most_common</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>


<div class="output highlight">
<pre>
    RETIRED                    4769520
    NOT EMPLOYED               2656988
    ATTORNEY                   1340434
    PHYSICIAN                   659082
    HOMEMAKER                   494187
                                ...   
    CHIEF EXECUTIVE OFFICER      26551
    SURGEON                      25521
    EDITOR                       25457
    OPERATOR                     25151
    ORTHOPAEDIC SURGEON          24384
    Name: occupation, Length: 100, dtype: int64
</pre>
</div>

<p>At this point, the task graph is handed to a <a href="https://dask.pydata.org/en/latest/scheduling.html">scheduler</a>, which is responsible for executing a task graph. Schedulers can analyze a task graph and find sections that can run <em>in parallel</em>. (Dask includes several schedulers. See <a href="http://dask.pydata.org/en/latest/scheduling.html">the scheduling documentation</a> for how to choose, though Dask has good defaults.)</p>
<p>So that's a high-level tour of how Dask works: </p>
<p><img alt="" src="http://dask.pydata.org/en/latest/_images/collections-schedulers.png"></p>
<ol>
<li>Various collections collections like <code>dask.dataframe</code> and <code>dask.array</code>
   provide users familiar APIs for working with large datasets.</li>
<li>Computations are represented as a task graph. These graphs could be built by
   hand, or more commonly built by one of the collections.</li>
<li>Dask schedulers run task graphs in parallel (potentially distributed across
   a cluster), reusing libraries like NumPy and pandas to do the computations.</li>
</ol>
<p>Let's finish off this post by continuing to explore the FEC dataset with Dask. At this point, we'll use the distributed scheduler for it's nice diagnostics.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="kn">as</span> <span class="nn">dd</span>
<span class="kn">from</span> <span class="nn">dask</span> <span class="kn">import</span> <span class="n">compute</span>
<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<p>Calling <code>Client</code> without providing a scheduler address will make a local "cluster" of threads or processes on your machine. There are <a href="http://dask.pydata.org/en/latest/setup.html">many ways</a> to deploy a Dask cluster onto an actual cluster of machines, though we're particularly fond of <a href="http://dask.pydata.org/en/latest/setup/kubernetes.html">Kubernetes</a>. This highlights one of my favorite features of Dask: it scales down to use a handful of threads on a laptop <em>or</em> up to a cluster with thousands of nodes. Dask can comfortably handle medium-sized datasets (dozens of GBs, so larger than RAM) on a laptop. Or it can scale up to very large datasets with a cluster.</p>
<div class="highlight"><pre><span></span><span class="n">individual_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cmte_id&#39;</span><span class="p">,</span> <span class="s1">&#39;entity_tp&#39;</span><span class="p">,</span> <span class="s1">&#39;employer&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;transaction_dt&#39;</span><span class="p">,</span> <span class="s1">&#39;transaction_amt&#39;</span><span class="p">]</span>

<span class="n">indiv</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s1">&#39;data/indiv-*.parq&#39;</span><span class="p">,</span>
                        <span class="n">columns</span><span class="o">=</span><span class="n">individual_cols</span><span class="p">,</span>
                        <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">indiv</span>
</pre></div>


<div class="output">
<div><strong>Dask DataFrame Structure:</strong></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cmte_id</th>
      <th>entity_tp</th>
      <th>employer</th>
      <th>occupation</th>
      <th>transaction_dt</th>
      <th>transaction_amt</th>
    </tr>
    <tr>
      <th>npartitions=5</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>datetime64[ns]</td>
      <td>int64</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>
<div>Dask Name: read-parquet, 5 tasks</div>
</div>

<p>We can compute summary statistics like the average mean and standard deviation of the transaction amount:</p>
<div class="highlight"><pre><span></span><span class="n">avg_transaction</span> <span class="o">=</span> <span class="n">indiv</span><span class="o">.</span><span class="n">transaction_amt</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>


<p>We can answer questions like "Which employer's employees donated the most?"</p>
<div class="highlight"><pre><span></span><span class="n">total_by_employee</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">indiv</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;employer&#39;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">transaction_amt</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>Or "what is the average amount donated per occupation?"</p>
<div class="highlight"><pre><span></span><span class="n">avg_by_occupation</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">indiv</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;occupation&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">transaction_amt</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>Since Dask is lazy, we haven't actually computed anything.</p>
<div class="highlight"><pre><span></span><span class="n">total_by_employee</span>
</pre></div>


<div class="output highlight">
<pre>
    Dask Series Structure:
    npartitions=1
        int64
          ...
    Name: transaction_amt, dtype: int64
    Dask Name: series-nlargest-agg, 13 tasks
</pre>
</div>

<p><code>avg_transaction</code>, <code>avg_by_occupation</code> and <code>total_by_employee</code> are three separate computations (they have different task graphs), but we know they share some structure: they're all reading in the same data, they might select the same subset of columns, and so on. Dask is able to avoid redundant computation when you use the top-level <code>dask.compute</code> function.</p>
<div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">avg_transaction</span><span class="p">,</span> <span class="n">by_employee</span><span class="p">,</span> <span class="n">by_occupation</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span>
    <span class="n">avg_transaction</span><span class="p">,</span> <span class="n">total_by_employee</span><span class="p">,</span> <span class="n">avg_by_occupation</span>
<span class="p">)</span>
</pre></div>


<div class="output highlight">
<pre>
    CPU times: user 57.5 s, sys: 14.4 s, total: 1min 11s
    Wall time: 54.9 s
</pre>
</div>

<div class="highlight"><pre><span></span><span class="n">avg_transaction</span>
</pre></div>


<div class="output highlight">
<pre>
    566.0899206077507
</pre>
</div>

<div class="highlight"><pre><span></span><span class="n">by_employee</span>
</pre></div>


<div class="output highlight">
<pre>
    employer
    RETIRED                1019973117
    SELF-EMPLOYED           834547641
    SELF                    537402882
    SELF EMPLOYED           447363032
    NONE                    418011322
    HOMEMAKER               355195126
    NOT EMPLOYED            345770418
    FAHR, LLC               166679844
    CANDIDATE                75186830
    ADELSON DRUG CLINIC      53358500
    Name: transaction_amt, dtype: int64
</pre>
</div>

<div class="highlight"><pre><span></span><span class="n">by_occupation</span>
</pre></div>


<div class="output highlight">
<pre>
    occupation
    CHAIRMAN CEO & FOUNDER                   1,023,333.33
    PAULSON AND CO., INC.                    1,000,000.00
    CO-FOUNDING DIRECTOR                       875,000.00
    CHAIRMAN/CHIEF TECHNOLOGY OFFICER          750,350.00
    CO-FOUNDER, DIRECTOR, CHIEF INFORMATIO     675,000.00
    CO-FOUNDER, DIRECTOR                       550,933.33
    MOORE CAPITAL GROUP, LP                    500,000.00
    PERRY HOMES                                500,000.00
    OWNER, FOUNDER AND CEO                     500,000.00
    CHIEF EXECUTIVE OFFICER/PRODUCER           500,000.00
    Name: transaction_amt, dtype: float64
</pre>
</div>

<p>Things like filtering work well. Let's find the 10 most common occupations and filter the dataset down to just those.</p>
<div class="highlight"><pre><span></span><span class="n">top_occupations</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">indiv</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
        <span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>
<span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">top_occupations</span>
</pre></div>


<div class="output highlight">
<pre>
    Index(['RETIRED', 'NOT EMPLOYED', 'ATTORNEY', 'PHYSICIAN', 'HOMEMAKER',
           'PRESIDENT', 'PROFESSOR', 'CONSULTANT', 'EXECUTIVE', 'ENGINEER'],
          dtype='object')
</pre>
</div>

<p>We'll filter the raw records down to just the ones from those occupations. Then we'll compute a few summary statistics on the transaction amounts for each group.</p>
<div class="highlight"><pre><span></span><span class="n">donations</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">indiv</span><span class="p">[</span><span class="n">indiv</span><span class="o">.</span><span class="n">occupation</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">top_occupations</span><span class="p">)]</span>
        <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;occupation&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">transaction_amt</span>
        <span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">total_avg</span><span class="p">,</span> <span class="n">occupation_avg</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="n">indiv</span><span class="o">.</span><span class="n">transaction_amt</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                                    <span class="n">donations</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">])</span>
</pre></div>


<p>These are small, concrete results so we can turn to familiar tools like matplotlib to visualize the result.</p>
<div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">occupation_avg</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.9</span><span class="p">);</span>
<span class="n">lim</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">total_avg</span><span class="p">,</span> <span class="o">*</span><span class="n">lim</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Average donation&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Donation Amount&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Average Dontation by Occupation&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="modern-pandas-08_files/modern-pandas-08_49_0.png"></p>
<p>Dask inherits all of pandas' great time-series support. We can get the total amount donated per day using a <a href="https://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling"><code>resample</code></a>.</p>
<div class="highlight"><pre><span></span><span class="n">daily</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">indiv</span><span class="p">[[</span><span class="s1">&#39;transaction_dt&#39;</span><span class="p">,</span> <span class="s1">&#39;transaction_amt&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
        <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;transaction_dt&#39;</span><span class="p">)[</span><span class="s1">&#39;transaction_amt&#39;</span><span class="p">]</span>
        <span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="s2">&quot;D&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">daily</span>
</pre></div>


<div class="output highlight">
<pre>
    1916-01-23    1000
    1916-01-24       0
    1916-01-25       0
    1916-01-26       0
    1916-01-27       0
                  ... 
    2201-05-29       0
    2201-05-30       0
    2201-05-31       0
    2201-06-01       0
    2201-06-02    2000
    Name: transaction_amt, Length: 104226, dtype: int64
</pre>
</div>

<p>It seems like we have some bad data. This should just be 2007-2016. We'll filter it down to the real subset before plotting.
Notice that the seamless transition from <code>dask.dataframe</code> operations above, to pandas operations below.</p>
<div class="highlight"><pre><span></span><span class="n">subset</span> <span class="o">=</span> <span class="n">daily</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;2011&#39;</span><span class="p">:</span><span class="s1">&#39;2016&#39;</span><span class="p">]</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subset</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Daily Donations&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;$ (thousands)&quot;</span><span class="p">,)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="modern-pandas-08_files/modern-pandas-08_54_0.png"></p>
<h2>Joining</h2>
<p>Like pandas, Dask supports joining together multiple datasets.</p>
<p>Individual donations are made to <em>committees</em>. Committees are what make the actual expenditures (buying a TV ad).
Some committees are directly tied to a candidate (this are campaign committees). Other committees are tied to a group (like the Republican National Committee). Either may be tied to a party.</p>
<p>Let's read in the committees. The total number of committees is small, so we'll <code>.compute</code> immediately to get a pandas DataFrame (the reads still happen in parallel!).</p>
<div class="highlight"><pre><span></span><span class="n">committee_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cmte_id&#39;</span><span class="p">,</span> <span class="s1">&#39;cmte_nm&#39;</span><span class="p">,</span> <span class="s1">&#39;cmte_tp&#39;</span><span class="p">,</span> <span class="s1">&#39;cmte_pty_affiliation&#39;</span><span class="p">]</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s2">&quot;data/cm-*.parq&quot;</span><span class="p">,</span>
                     <span class="n">columns</span><span class="o">=</span><span class="n">committee_cols</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="c1"># Some committees change thier name, but the ID stays the same</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cmte_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">last</span><span class="p">()</span>
<span class="n">cm</span>
</pre></div>


<div class="output highlight">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table  class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cmte_nm</th>
      <th>cmte_tp</th>
      <th>cmte_pty_affiliation</th>
    </tr>
    <tr>
      <th>cmte_id</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>C00000042</th>
      <td>ILLINOIS TOOL WORKS INC. FOR BETTER GOVERNMENT...</td>
      <td>Q</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C00000059</th>
      <td>HALLMARK CARDS PAC</td>
      <td>Q</td>
      <td>UNK</td>
    </tr>
    <tr>
      <th>C00000422</th>
      <td>AMERICAN MEDICAL ASSOCIATION POLITICAL ACTION ...</td>
      <td>Q</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C00000489</th>
      <td>D R I V E POLITICAL FUND CHAPTER 886</td>
      <td>N</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C00000547</th>
      <td>KANSAS MEDICAL SOCIETY POLITICAL ACTION COMMITTEE</td>
      <td>Q</td>
      <td>UNK</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>C90017237</th>
      <td>ORGANIZE NOW</td>
      <td>I</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C90017245</th>
      <td>FRANCISCO AGUILAR</td>
      <td>I</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C90017336</th>
      <td>LUDWIG, EUGENE</td>
      <td>I</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C99002396</th>
      <td>AMERICAN POLITICAL ACTION COMMITTEE</td>
      <td>Q</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>C99003428</th>
      <td>THIRD DISTRICT REPUBLICAN PARTY</td>
      <td>Y</td>
      <td>REP</td>
    </tr>
  </tbody>
</table>
<p>28612 rows × 3 columns</p>
</div>
</div>

<p>We'll use <code>dd.merge</code>, which is analogous to <code>pd.merge</code> for joining a Dask <code>DataFrame</code> with a pandas or Dask <code>DataFrame</code>.</p>
<div class="highlight"><pre><span></span><span class="n">indiv</span> <span class="o">=</span> <span class="n">indiv</span><span class="p">[(</span><span class="n">indiv</span><span class="o">.</span><span class="n">transaction_dt</span> <span class="o">&gt;=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="s2">&quot;2007-01-01&quot;</span><span class="p">))</span> <span class="o">&amp;</span>
              <span class="p">(</span><span class="n">indiv</span><span class="o">.</span><span class="n">transaction_dt</span> <span class="o">&lt;=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="s2">&quot;2018-01-01&quot;</span><span class="p">))]</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">indiv</span><span class="p">,</span> <span class="n">cm</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;cmte_id&#39;</span><span class="p">)</span>
<span class="n">df2</span>
</pre></div>


<div class="output highlight">
<div><strong>Dask DataFrame Structure:</strong></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table  class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cmte_id</th>
      <th>entity_tp</th>
      <th>employer</th>
      <th>occupation</th>
      <th>transaction_dt</th>
      <th>transaction_amt</th>
      <th>cmte_nm</th>
      <th>cmte_tp</th>
      <th>cmte_pty_affiliation</th>
    </tr>
    <tr>
      <th>npartitions=20</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>datetime64[ns]</td>
      <td>int64</td>
      <td>object</td>
      <td>object</td>
      <td>object</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>
<div>Dask Name: merge, 141 tasks</div>
</div>

<p>Now we can find which party raised more over the course of each election. We'll group by the day and party and sum the transaction amounts.</p>
<div class="highlight"><pre><span></span><span class="n">indiv</span> <span class="o">=</span> <span class="n">indiv</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">indiv</span><span class="p">,</span> <span class="n">cm</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;cmte_id&#39;</span><span class="p">)</span>
<span class="n">df2</span>
</pre></div>


<div class="output highlight">
<div><strong>Dask DataFrame Structure:</strong></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table  class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cmte_id</th>
      <th>entity_tp</th>
      <th>employer</th>
      <th>occupation</th>
      <th>transaction_dt</th>
      <th>transaction_amt</th>
      <th>cmte_nm</th>
      <th>cmte_tp</th>
      <th>cmte_pty_affiliation</th>
    </tr>
    <tr>
      <th>npartitions=10</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>object</td>
      <td>datetime64[ns]</td>
      <td>int64</td>
      <td>object</td>
      <td>object</td>
      <td>object</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th></th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>
<div>Dask Name: merge, 141 tasks</div>
</div>

<div class="highlight"><pre><span></span><span class="n">party_donations</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df2</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">df2</span><span class="o">.</span><span class="n">transaction_dt</span><span class="p">,</span> <span class="s1">&#39;cmte_pty_affiliation&#39;</span><span class="p">])</span>
       <span class="o">.</span><span class="n">transaction_amt</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
</pre></div>


<p>We'll filter that down to just Republican and Democrats and plot.</p>
<div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">party_donations</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;REP&#39;</span><span class="p">,</span> <span class="s1">&#39;DEM&#39;</span><span class="p">]]</span>
        <span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="s2">&quot;cmte_pty_affiliation&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="s1">&#39;30D&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="s1">&#39;C3&#39;</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
                                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Daily Donations (30-D Moving Average)&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Date&quot;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="modern-pandas-08_files/modern-pandas-08_64_0.png"></p>
<h2>Try It Out!</h2>
<p>So that's a taste of Dask. Next time you hit a scaling problem with pandas (or NumPy, scikit-learn, or your custom code), feel free to</p>
<div class="highlight"><pre><span></span>pip install dask[complete]
</pre></div>


<p>or</p>
<div class="highlight"><pre><span></span>conda install dask
</pre></div>


<p>The <a href="http://dask.pydata.org/en/latest/">dask homepage</a> has links to all the relevant documentation, and <a href="https://mybinder.org/v2/gh/dask/dask-examples/master?filepath=dataframe.ipynb">binder notebooks</a> where you can try out Dask before installing.</p>
<p>As always, reach out to me on <a href="https://twitter.com/TomAugspurger">Twitter</a> or in the comments if you have anything to share.</p>
  </div>

</article>


  </main>
    <footer>
      <div class="author__logo">
          <img src="/theme/images/logo.png" alt="logo">
      </div>
      <section class="author">
        <div class="author__name">
          <a href="/pages/about.html">Tom Augspurger</a>
          <p></p>
        </div>
        <div class="author__link">
          <ul>
            <li><a href="/pages/about.html" title="About"><i class="fa fa-link"></i></a></li>
            <li><a href="/pages/article-1-cluster.html" title="article-1-cluster"><i class="fa fa-link"></i></a></li>
            <li>
              <a href="/feeds/all.atom.xml" target="_blank" title="Feed">
                <i class="fa fa-rss"></i>
              </a>
            </li>
          </ul>
        </div>
      </section>
      <div class="ending-message">
        <p>&copy; Tom Augspurger. Powered by <a href="http://getpelican.com" target="_blank">Pelican</a>, Theme is using <a href="https://github.com/laughk/pelican-hss" target="_blank">HSS</a>. </p>
      </div>
    </footer>
</body>
</html>