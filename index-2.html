<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
    <head>
    <meta charset="utf-8">
    <meta name="description" content="Data Science. Stats. Pandas.">
    <meta name="viewport" content="width=device-width">
    <title>Tom's Blog (old posts, page 2) | Tom's Blog</title>

                <link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">

                <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

      <link rel="canonical" href="http://tomaugspurger.github.io/index-2.html">



    
        <!--[if lt IE 9]><script src="/assets/js/html5.js"></script><![endif]-->

    

    
    <style>
    div.input_prompt {
      display: none;
    }
    </style>

</head>
<body>
    <section class="social">
        <ul>
                    <li><a href="index.html" title="Home"><i class="icon-home"></i></a></li>
            <li><a href="archive.html" title="Archives"><i class="icon-folder-open-alt"></i></a></li>
            <li><a href="categories/index.html" title="Tags"><i class="icon-tags"></i></a></li>
            <li><a href="rss.xml" title="RSS"><i class="icon-rss"></i></a></li>

        </ul>
    </section>
    <section class="page-content">
        <div class="content" rel="main">
        <div class="post">
            <h1 class="title"><a href="posts/setting-up.html">Setting Up</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-08-16T00:00:00-05:00">2014-08-16 00:00</time>
                </div>
                <div class="stats">
                    
                </div>
                
            </div>
            <div class="body">
                <div>
<p>I needed to clean up my dev environment, so these are my notes for getting my mac running.
Mostly from memory and mostly for my future self, so be warned.</p>
<h4>Package Management</h4>
<p>Use homebrew. If you can get by with the Xcode Command Line Tools, do that.</p>
<pre class="code literal-block">xcode-select install
</pre>


<p>Some applications (like MacVim) require a full installatoin of Xcode, which you can get off the App Store.</p>
<p>Once you have that, get homebrew with</p>
<pre class="code literal-block">ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"
</pre>


<h4>Shell</h4>
<p>I use fish-shell.</p>
<pre class="code literal-block">brew install fish
</pre>


<p>Here's my <code>config.fish</code>.
I use virtualfish, which I keep in <code>~/.config/fish/virtualfish.</code></p>
<h4>Python</h4>
<p>I try to not mess with the System python.
So get the homebrew python setup as early as possible.</p>
<pre class="code literal-block">brew install python
brew install python3

pip intsall virtualenv
pip install virtualenvwrapper
</pre>


<p>You should <em>always</em> use virtualenvs.
My virtualenv home is in <code>~/Envs/</code>.</p>
<h4>Scientific Python</h4>
<p>For the numpy stack.
May need some C libraries.</p>
<pre class="code literal-block">brew install libxml2
brew install libxlst
brew install hdf5
brew install zeromq
</pre>


<p>Now for the python stuff.</p>
<pre class="code literal-block">workon &lt;virtualenv&gt;
cdsitepackages

pip install numpy
pip install scipy
pip install cython pytz python-dateutil
pip install numexpr bottleneck 
pip install lxml beautifulsoup4 tables xlrd xlwt html5lib nose
pip install jinja2 pyzmq

git clone https://github.com/pydata/pandas
git clone https://github.com/statsmodels/statsmodels
git clone https://github.com/matplotlib/matplotlib
git clone https://github.com/ipython/ipython
</pre>


<p>Then do the usual <code>cd</code>ing into those git repos. For pandas
I build the C extensions inplace</p>
<pre class="code literal-block">python setup.py build_ext --inplace; and python setup.py install
</pre>


<p>For IPython make sure to init and update their submodules with
<code>python setup.py submodule</code>.</p>
<h4>Blog</h4>
<p>Using the pelican static site generator.</p>
<pre class="code literal-block">vf new blog
pip install pelican markdown
git clone https://github.com/TomAugspurger/blog-source.git
</pre>


<h4>Editor</h4>
<p>I'm slowly switching over to Vim/MacVim.</p>
<pre class="code literal-block">brew unlink python  # I'll explain later
brew install vim --override-system-vim
brew install macvim
</pre>


<p>Manage plugins with Vundle.</p>
<p>I had some trouble with YCM picking up the wrong python and crashing.
Make sure to set the path in your vimrc. For some reason, MacVim compiled
with the system python rather than homebrew (which came first on my path),
so I directed YCM to it.</p>
<pre class="code literal-block">cd ~/.vim/bundle/YouCompleteMe/
./install.sh
brew link python
</pre>


<p>Then in your .vimrc point YCM to the System python,
the one macvim complied agains.</p>
<pre class="code literal-block">let g:ycm_path_to_python_interpreter = '/usr/bin/python'
</pre>


<p>I only got it working when I first <code>brew unlink python</code> before brewing
macvim. So the order should be</p>
<pre class="code literal-block">brew unlink python
brew install macvim
./install.sh  # in ~/.vim/bundle/YouCompleteMe
brew link python
</pre>


<h4>Haskell</h4>
<p>I tried out <a href="http://ghcformacosx.github.io">ghcformacosx</a>;
we'll see how well it goes.
I unzipped the app to <code>/Applications</code> and made a symlink to it
so that I don't have to chagne my path every time ghc is updated.</p>
<pre class="code literal-block">ln -s /Applications/ghc-7.8.3.app /Applications/ghc.app
</pre>


<p>Here's my <code>ghci.conf</code> and my <code>~/.cabal/config</code>.
I'm experiementing with always using cabal sandboxes.
However, I'd like hdevtools and such to always be available for editing.
There's probably a way to share those across libraries, so I could put
them on their own sandbox, but for now I'll just install them globally.</p>
<p>I had to manually install happy and haskell-src-exts. </p>
<pre class="code literal-block">cabal update
cabal install cabal-install

cabal install happy
cabal install haskell-src-ext-1.15.0.1
</pre>


<pre class="code literal-block">cabal install hdevtools ghc-mode hlint
</pre>


<p>I'm also trying out lushtags, which I had to <a href="https://github.com/TomAugspurger/lushtags">fork</a>
to adjust the cabal requirements.</p>
<p>Install with</p>
<pre class="code literal-block">cabal configure
cabal build
cabal install
</pre>


<p>Then uncomment the line <code>-- require-sandbox: True</code> in your <code>~/.cabal/config</code>.</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/tackling%20the%20cps%20(part%204).html">Using Python to tackle the CPS (Part 4)</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-05-19T12:01:00-05:00">2014-05-19 12:01</time>
                </div>
                <div class="stats">
                    
                </div>
                
            </div>
            <div class="body">
                <div>
<p>Last time, we got to where we'd like to have started: One file per month, with each month laid out the same.</p>
<p>As a reminder, the CPS interviews households 8 times over the course of 16 months. They're interviewed for 4 months, take 8 months off, and are interviewed four more times. So if your first interview was in month $m$, you're also interviewed in months $$m + 1, m + 2, m + 3, m + 12, m + 13, m + 14, m + 15$$.</p>
<p>I stored the data in <a href="http://pandas-docs.github.io/pandas-docs-travis/dsintro.html#panel">Panels</a>, the less well-known, higher-dimensional cousin of the <a href="http://pandas.pydata.org/pandas-docs/version/0.13.1/generated/pandas.DataFrame.html">DataFrame</a>. Panels are 3-D structures, which is great for this kind of data. The three dimensions are</p>
<ol>
<li>items: Month in Survey (0 - 7)</li>
<li>fields: Things like employment status, earnings, hours worked</li>
<li>id: An identifier for each household</li>
</ol>
<p>Think of each item as a 2-D slice (a DataFrame) into the 3-D Panel. So each household is described by a single Panel (or 8 DataFrames).</p>
<p>The actual panel construction occurs in <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_panel.py#L151"><code>make_full_panel</code></a>. Given a starting month, it figures out the months needed to generate that wave's Panel ($m, m + 1, m + 2, \ldots$), and stores these in an iterator called <code>dfs</code>.
Since each month on disk contains people from 8 different waves (first month, second month, ...), I filter down to just the people in their $i^{th}$ month in the survey, where $i$ is the month I'm interested in.
Everything up until this point is done lazily; nothing has actually be read into memory yet.</p>
<p>Now we'll read in each month, storing each month's DataFrame in a dictionary, <code>df_dict</code>. We take the first month as is.
Each subsequent month has to be matched against the first month.</p>
<pre class="code literal-block">    <span class="n">df_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="n">df1</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dfn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dfs</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">df_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">match_panel</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">dfn</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s">'panel_log'</span><span class="p">])</span>
    <span class="c"># Lose dtype info here if I just do from dict.</span>
    <span class="c"># to preserve dtypes:</span>
    <span class="n">df_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">df_dict</span><span class="o">.</span><span class="n">iteritems</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">}</span>
    <span class="n">wp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Panel</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">df_dict</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">'minor'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wp</span>
</pre>


<p>In an ideal world, we just check to see if the indexes match (the unique identifier). However, the unique ID given by the Census Bureau isn't so unique, so we use some heuristics to guess if the person is actually the same as the one interviewed next week. <code>match_panel</code> basically checks to see if a person's race and gender hasn't changed, and that their age has changed by less than a year or so.</p>
<p>There's a bit more code that handles special cases, errors, and the writing of the output.
I was especially interested in earnings data, so I wrote that out separately.
But now we're finally to the point where we can do some analysis:</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/tackling%20the%20cps%20(part%203).html">Using Python to tackle the CPS (Part 3)</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-05-19T12:00:00-05:00">2014-05-19 12:00</time>
                </div>
                <div class="stats">
                    
                </div>
                
            </div>
            <div class="body">
                <div>
<p>In <a href="http://tomaugspurger.github.io/blog/2014/02/04/tackling%20the%20cps%20(part%202)/">part 2</a> of this series, we set the stage to parse the data files themselves.</p>
<p>As a reminder, we have a dictionary that looks like</p>
<pre class="code literal-block">         <span class="nb">id</span>  <span class="n">length</span>  <span class="n">start</span>  <span class="n">end</span>
<span class="mi">0</span>    <span class="n">HRHHID</span>      <span class="mi">15</span>      <span class="mi">1</span>   <span class="mi">15</span>
<span class="mi">1</span>   <span class="n">HRMONTH</span>       <span class="mi">2</span>     <span class="mi">16</span>   <span class="mi">17</span>
<span class="mi">2</span>   <span class="n">HRYEAR4</span>       <span class="mi">4</span>     <span class="mi">18</span>   <span class="mi">21</span>
<span class="mi">3</span>  <span class="n">HURESPLI</span>       <span class="mi">2</span>     <span class="mi">22</span>   <span class="mi">23</span>
<span class="mi">4</span>   <span class="n">HUFINAL</span>       <span class="mi">3</span>     <span class="mi">24</span>   <span class="mi">26</span>
         <span class="o">...</span>     <span class="o">...</span>    <span class="o">...</span>  <span class="o">...</span>
</pre>


<p>giving the columns of the raw CPS data files. This post (or two) will describe the reading of the actual data files, and the somewhat tricky process of matching individuals across the different files. After that we can (finally) get into analyzing the data. The old joke is that statisticians spend 80% of their time munging their data, and 20% of their time complaining about munging their data. So 4 posts about data cleaning seems reasonable.</p>
<p>The data files are stored in fixed width format (FWF), one of the least human friendly ways to store data.
We want to get to an <a href="http://www.hdfgroup.org/HDF5/">HDF5</a> file, which is extremely fast and convinent with pandas.</p>
<p>Here's the first line of the raw data:</p>
<pre class="code literal-block">head -n 1 /Volumes/HDD/Users/tom/DataStorage/CPS/monthly/cpsb9401
881605952390 2  286-1 2201-1 1 1 1-1 1 5-1-1-1  22436991 1 2 1 6 194 2A61 -1 2 2-1-1-1-1 363 1-15240115 3-1 4 0 1-1 2 1-1660 1 2 2 2 6 236 2 8-1 0 1-1 1 1 1 2 1 2 57 57 57 1 0-1 2 5 3-1-1 2-1-1-1-1-1 2-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1 -1-1  169-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 -1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 2-1 0 4-1-1-1-1-1-1 -1-1-1 0 1 2-1-1-1-1-1-1-1-1-1 -1 -1-1-1 -1 -1-1-1 0-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 0-1-1-1-1-1  -1  -1  -1  0-1-1      0-1-1-1      -1      0-1-1-1-1-1-1-1-1 2-1-1-1-1  22436991        -1         0  22436991  22422317-1         0 0 0 1 0-1 050 0 0 0 011 0 0 0-1-1-1-1 0 0 0-1-1-1-1-1-1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1 1 1 1 1 1 1 1 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1 1 1 1-1-1-1
</pre>


<p>We'll use pandas' <a href="http://pandas.pydata.org/pandas-docs/version/0.13.0/generated/pandas.io.parsers.read_fwf.html#pandas.io.parsers.read_fwf"><code>read_fwf</code></a> parser, passing in the widths we got from last post.
One note of warning, the <code>read_fwf</code> function is slow. It's written in plain python, and really makes you appreciate <a href="http://wesmckinney.com/blog/?p=543">all the work</a> Wes (the creater or pandas) put into making <code>read_csv</code> fast.</p>
<p>Start by looking at the <code>__main__</code> <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L786">entry point</a>. The basic idea is to call <code>python make_hdf.py</code> with an optional argument giving a file with a specific set of months you want to process. Otherwise, it processes every month in your data folder. There's a bit of setup to make sure everything is order, and then we jump to the <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L813">next important line</a>:</p>
<pre class="code literal-block"><span class="k">for</span> <span class="n">month</span> <span class="ow">in</span> <span class="n">months</span><span class="p">:</span>
    <span class="n">append_to_store</span><span class="p">(</span><span class="n">month</span><span class="p">,</span> <span class="n">settings</span><span class="p">,</span> <span class="n">skips</span><span class="p">,</span> <span class="n">dds</span><span class="p">,</span> <span class="n">start_time</span><span class="o">=</span><span class="n">start_time</span><span class="p">)</span>
</pre>


<p>I'd like to think that <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L725">this function</a> is fairly straightforward. We generate the names I use internally (<code>name</code>), read in the data dictionary that we parsed last time (<code>dd</code> and <code>widths</code>), and get to work reading the actual data with</p>
<pre class="code literal-block"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_fwf</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s">'.gz'</span><span class="p">,</span> <span class="n">widths</span><span class="o">=</span><span class="n">widths</span><span class="p">,</span>
                 <span class="n">names</span><span class="o">=</span><span class="n">dd</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s">'gzip'</span><span class="p">)</span>
</pre>


<p>Rather than stepping through every part of the processing (checking types, making sure indexes are unique, handling missing values, etc.) I want to focus on one specific issue: handling special cases. Since the CPS data aren't consistent month to month, I needed a way transform the data for certain months differently that for others. The design I came up with worked pretty well.</p>
<p>The solution is in <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L603"><code>special_by_dd</code></a>. Basically, each data dictionary (which describes the data layout for a month) has its own little quirks.
For example, the data dictionary starting in January 1989 spread the two digits for age across two fields. The fix itself is extremely simple: <code>df["PRTAGE"] = df["AdAGEDG1"] * 10 + df["AdAGEDG2"]</code>, but knowing when to apply this fix, and how to apply several of these fixes is the interesting part.</p>
<p>In <a href="https://github.com/TomAugspurger/dnwr-zlb/blob/master/data_wrangling/cps_wrangling/panel_construction/make_hdf_store.py#L603"><code>special_by_dd</code></a>, I created a handful of closures (basically just functions inside other functions), and a dictionary mapping names to those functions.</p>
<pre class="code literal-block"><span class="n">func_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"expand_year"</span><span class="p">:</span> <span class="n">expand_year</span><span class="p">,</span> <span class="s">"combine_age"</span><span class="p">:</span> <span class="n">combine_age</span><span class="p">,</span>
             <span class="s">"expand_hours"</span><span class="p">:</span> <span class="n">expand_hours</span><span class="p">,</span> <span class="s">"align_lfsr"</span><span class="p">:</span> <span class="n">align_lfsr</span><span class="p">,</span>
             <span class="s">"combine_hours"</span><span class="p">:</span> <span class="n">combine_hours</span><span class="p">}</span>
</pre>


<p>Each one of these functions takes a DataFrame and returns a DataFrame, with the fix applied. The example above is <code>combine_age</code>.
In a settings file, I had a JSON object mapping the data dictionary name to special functions to apply. For example, January 1989's special case list was:</p>
<pre class="code literal-block">"jan1989": ["expand_year", "combine_age", "align_lfsr", "expand_hours", "combine_hours"]
</pre>


<p>I get the necessary special case functions and apply each with</p>
<pre class="code literal-block">specials = special_by_dd(settings["special_by_dd"][dd_name])
for func in specials:
    df = specials[func](df, dd_name)
</pre>


<p><code>specials</code> is just <code>func_dict</code> from above, but filtered to be only the functions specified in the settings file.
We select the function from the dictionary with <code>specials[func]</code> and then directly call it with <code>(df, dd_name)</code>.
Since functions are objects in python, we're able to store them in dictionaries and pass them around like just about anything else.</p>
<p>This method gave a lot of flexibility. When I discovered a new way that one month's layout differed from what I wanted, I simply wrote a function to handle the special case, added it to <code>func_dict</code>, and added the new special case to that month's speical case list.</p>
<p>There's a bit more standardization and other boring stuff that gets us to a good place: each month with the same layout. Now we get get to the tricky alignment, which I'll save for another post.</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/Quiz%2010%20Review.html">Stats for Strategy Quiz 10 Review</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-05-01T12:00:00-05:00">2014-05-01 12:00</time>
                </div>
                <div class="stats">
                    
                </div>
                        <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="categories/review.html" rel="tag">review</a></li>
           <li><a class="tag p-category" href="categories/stats-for-strategy.html" rel="tag">stats for strategy</a></li>
        </ul>
        </div>

            </div>
            <div class="body">
                <div>
<p>This was our first week of Time Series Analysis, and we covered smoothing methods and autocorrelation. Overall, the scores were pretty good. If you have any questions going into the final, let me know. I'll be around.</p>
<h2>Section A01</h2>
<p>This quiz focused on exponential smoothing. Make sure that you know about moving averages and autocorrelation too.</p>
<h4>#1</h4>
<p>You needed to find the biggest decline in the time series.
You should never have to guess in stats, and I'm worried that some of you just looked at the graph and guessed the right week.
I'd suggest plotting the series to get an idea of where the biggest declines were.
Then you can go into the dataset and verify that the biggest decline was the the week of 2007-07-21.</p>
<h4>#2</h4>
<p>The model that provides the most smoothing will <em>always</em> be the model with the lowest $w$, $w=.10$ in this case.
This puts 10% of the weight on the most recent observation, and 90% on prior observations, which means that the exponentially smoothed prediction won't jump around a lot in response to one day's change.</p>
<p>For part $d$, some people got returned an interval. It was only asking for a single number though, the prediction error: $e_t = y_t - \hat{y}_t$. If it had asked for a prediction error with $x$% confidence, then you should return an interval.</p>
<p>I'm not sure if anyone got the extra credit. This was like the Cubs example we did in class. For ES models, the prediction for tomorrow depends on the entire history. This means we need to fit our model to the entire dataset. But, part $f$ was specifically concerned with the accuracy of <em>future</em> forecasts. So even though we fit the model to the whole dataset, we only are interested in the residuals of 2008. Copy-paste those up to a new column and calculate the MSE.</p>
<h2>Section B42</h2>
<p>This quiz focused on moving averages. Make sure that you know about exponential smoothing and autocorrelation too.</p>
<h4>#1</h4>
<p>You needed to find the biggest decline in the time series.
You should never have to guess in stats, and I'm worried that some of you just looked at the graph and guessed the right week.
I'd suggest plotting the series to get an idea of where the biggest declines were.
Then you can go into the dataset and verify that the biggest decline was the the week of 2007-07-21.</p>
<h4>#2</h4>
<p>The model that provides the most smoothing will <em>always</em> be the model with the highest $k$, $k=12$ in this case.
This averages the last $k$ periods when forecasting for tomorrow, which means that the moving average won't jump around a lot in response to one just one day's change.</p>
<p>For part $d$, some people got returned an interval. It was only asking for a single number though, the prediction error: $e_t = y_t - \hat{y}_t$. If it had asked for a prediction error with $x$% confidence, then you should return an interval.</p>
<p>I'm not sure if anyone got the extra credit. This was like the Cubs example we did in class. For MA models, we don't want to lose a prediction for the first $k$ periods, so we need to fit our model to the entire dataset. But, part $f$ was specifically concerned with the accuracy of <em>future</em> forecasts. So even though we fit the model to the whole dataset, we only are interested in the residuals of 2008. Copy-paste those up to a new column and calculate the MSE.</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/Quiz%208%20Review.html">Stats for Strategy Quiz 8 Review</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-04-10T17:00:00-05:00">2014-04-10 17:00</time>
                </div>
                <div class="stats">
                    
                </div>
                        <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="categories/review.html" rel="tag">review</a></li>
           <li><a class="tag p-category" href="categories/stats-for-strategy.html" rel="tag">stats for strategy</a></li>
        </ul>
        </div>

            </div>
            <div class="body">
                <div>
<p>Good luck on the exam.
Don't forget your section number!</p>
<h2>Section A01</h2>
<h3>#2</h3>
<p>Remember that for the modified best conservative model, we still care about the significance of all the predictors other than the ones that must be included.</p>
<h3>#3</h3>
<p>Quite a few people are still giving point estimates (just $\hat{y}$) when the question asks you to predict $y$ with some % certainty.
If you're asked to predict something with 95% certainty, your answer should be an interval.</p>
<h3>#4</h3>
<p>Make sure to use the right model for each question.
This one asks us to go back to the best conservative model (from #1).
Also, <code>Forearm</code> can still be interpreted, despite not being in the model.
We just say that it is unrelated to <code>BP</code>, after accounting for the other two predictors.</p>
<h3>#5</h3>
<p>We want the most accurate estimate of $\beta_{calf}$, so we'll use the full model (see p. 134 in the notebook).
Including insignificant predictors will increase the variance of your $\hat{y}$'s.
But for this problem we're only interested in the slope, so we'll include all the predictors, even if they aren't significant.</p>
<h2>Section B42</h2>
<p>Make sure to understand the goal of the drop method: find the model that gives us the most accurate predictions (best $\hat{y}$'s), i.e. the best conservative model.
The drop method is a fast way to (usually) get the best conservative model when you have many predictors.</p>
<p>For part c, we can still interpret predictors that aren't included in the model.
Each of them is unrelated to blood pressure after controlling for the variables you did include in the model.</p>
<p>The last question asks you to interpret the slope for <code>Age</code> from the simple regression model.
First of all, make sure to use the simple regression model; <code>Age</code> should be the only predictor.
Since <code>Age</code> is a binary variable, the interpretation is a bit different than usual.
Instead of saying "For every 1 unit increase in <code>Age</code>, <code>BP</code> changes by $\hat{\beta_1}$", we just compare the two groups.
Since $\hat{\beta_1} = 2.5$, we can say that "On average, people older than 40 (<code>Age</code>=1) have 2.50 points higher blood pressure than people younger than 40."</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/Quiz%207%20Review.html">Stats for Strategy Quiz 7 Review</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-04-04T12:00:00-05:00">2014-04-04 12:00</time>
                </div>
                <div class="stats">
                    
                </div>
                        <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="categories/review.html" rel="tag">review</a></li>
           <li><a class="tag p-category" href="categories/stats-for-strategy.html" rel="tag">stats for strategy</a></li>
        </ul>
        </div>

            </div>
            <div class="body">
                <div>
<h2>Section A01</h2>
<h3>#1</h3>
<p>The test statistic for $H_0: \beta_1 = \beta_2 = 0$ is the $F$ statistic. It's what we'll use for when we're testing multiple parameters at once.</p>
<p>Several people had $\beta_1 = 0$ <strong>or</strong> $\beta_2 = 0$.
This is wrong; it should be <strong>and</strong> not <strong>or</strong>.
This is actually an important difference since the distribution for the $F$ statistic is testing for both slopes simultaneously being zero.</p>
<h3>#2</h3>
<p>This one is similar to #1, except we're testing a single parameter.
That means we want the $t$ statistic.
We want the $t$ from the full model, since we're interested in if winterizing is a significant predictor after accounting for thermostat setting.</p>
<h3>#3</h3>
<p>Standard interpretation for a multiple regression slope.
Make sure to explain that this is the slope for <code>Winter</code>, when holding <code>Therm</code> constant.</p>
<h3>#4</h3>
<p>Similar to #3, but from the simple regression model.
We know we want the simple regression since we're asked for the <em>total effect</em> (not controlling for anything else).</p>
<p>Some people were mixing up the response and the predictor variables in the interpretation.
Remember, the slope is $\frac{\Delta y}{\Delta x}$. We change $x$ (the predictor) and see how $y$ responds.
To keep the interpretation simple, we change $x$ by one unit. Then the change in $y$ is the estimated slope $\hat{\beta}$.</p>
<h3>#5</h3>
<p>The direct effect is the slope from the full regression model.
It's the direct effect since we've controlled for all the other predictors,
there's nothing else included in the slope.</p>
<h2>Section B42</h2>
<h3>#1</h3>
<p>The test statistic for $\beta_1 = \beta_2 = \beta_3 = 0$ is the $F$ statistic. It's what we'll use for when we're testing multiple parameters at once.</p>
<p>Several people had $\beta_1 = 0$ <strong>or</strong> $\beta_2 = 0$ <strong>or</strong> $\beta_3 = 0$.
This is wrong; it should be <strong>and</strong> not <strong>or</strong>.
This is actually an important difference since the distribution for the $F$ statistic is testing for both slopes simultaneously being zero.</p>
<h3>#2</h3>
<p>Be careful to not mix up interpreting slopes vs. interpreting tests. #2 asked for you to interpret the result of a $t$ test: is $X_2$ is significant predictor of $y$, after controlling for the other predictors?</p>
<h3>#3</h3>
<p>Make sure you know what all you're controlling for when interpreting slopes.
For this one the best conservative model only had <code>HSM</code> as a predictor.
That means our interpretation of $\hat{B_1}$ doesn't include controlling for the other predictors.</p>
<p>For the prediction in part <code>c</code>, a lot of people made the same mistake as last week: they reported the point estimate $\hat{y}$, instead of an interval.
The question asked us to estimate with 90% certainty, so we know the answer should be an interval.</p>
<h3>#4</h3>
<p>The population regression equation is</p>
<p>\begin{equation}
    y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon
\end{equation}</p>
<p>where the $\beta_i$'s are unknown.
We want to slice out the subsection of the population with the grades given in the question.
Substitute those in for the $X_i$'s.
This is still a population regression equation (but for a subset of the population), so the $\beta_i$'s are still unknown.</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/Quiz%206%20Review.html">Stats for Strategy Quiz 6 Review</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-03-28T12:00:00-05:00">2014-03-28 12:00</time>
                </div>
                <div class="stats">
                    
                </div>
                        <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="categories/review.html" rel="tag">review</a></li>
           <li><a class="tag p-category" href="categories/stats-for-strategy.html" rel="tag">stats for strategy</a></li>
        </ul>
        </div>

            </div>
            <div class="body">
                <div>
<p>For parts <strong>b</strong> and <strong>d</strong> we wanted intervals.</p>
<p>Part <strong>b</strong> asked for a CI for the slope $\beta_1$. For this one you use the formula $\hat{\beta_1} \pm t^{\ast}_{n-p-1} SE(\hat{\beta_1})$. $n$ is the sample size and $p$ is the number of predictors (1 in this case).</p>
<p>You get the $\hat{\beta_1}$ and $SE(\hat{\beta_1})$
from a computer or calculator and lookup the $t^{\ast}$
in the table.
Remember to round the degrees of freedom down when looking up
$t^{\ast}$
in the table.
We want to be conservative and not overstate our sample size.</p>
<p>Part <strong>d</strong> asked for a different kind of interval, one for a $\hat{y}$.</p>
<p>For this kind of problem, you'll use either $\hat{y} \pm t^{\ast} SE_{\hat{\mu}}$ or $\hat{y} \pm t^{\ast} SE_{\hat{y}}$, depending on whether you are predicting for all observations with that value of $X$ or for a single observation.</p>
<p>We don't give you the formulas for the $SE_{\hat{\mu}}$ or $SE_{\hat{y}}$. Minitab gives the $SE_{\hat{\mu}}$ (they call it SE-Fit). So in practice you'll just take the CI or PI from the Minitab output.</p>
<p>If you're struggling with the Minitab or stats part of this stuff, let me know. Send me an email <a href="mailto:thomas-augspurger@uiowa.edu">thomas-augspurger@uiowa.edu</a> or stop by my office hours: Tuesdays from 10:30 - 11:30 and 12:30 - 1:30 (or by appointment). I want you to be comfortable with the basics of regression; the rest of the course builds on what we did last week.</p>
</div>
            </div>
        </div>
        <div class="post">
            <h1 class="title"><a href="posts/Tidy%20Data%20in%20Action.html">Tidy Data in Action</a></h1>
            <div class="meta">
                <div class="authordate">
                    <time class="timeago" datetime="2014-03-27T16:00:00-05:00">2014-03-27 16:00</time>
                </div>
                <div class="stats">
                    
                </div>
                        <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="categories/data-science.html" rel="tag">data science</a></li>
           <li><a class="tag p-category" href="categories/python.html" rel="tag">python</a></li>
           <li><a class="tag p-category" href="categories/scripts.html" rel="tag">scripts</a></li>
        </ul>
        </div>

            </div>
            <div class="body">
                <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="http://had.co.nz">Hadley Whickham</a> wrote a famous paper (for a certain definition of famous) about the importance of <a href="http://vita.had.co.nz/papers/tidy-data.pdf">tidy data</a> when doing data analysis.
I want to talk a bit about that, using an example from a StackOverflow post, with a solution using <a href="http://pandas.pydata.org">pandas</a>. The principles of tidy data aren't language specific.</p>
<p>A tidy dataset must satisfy three criteria (page 4 in <a href="http://vita.had.co.nz/papers/tidy-data.pdf">Whickham's paper</a>):</p>
<ol>
<li>Each variable forms a column.</li>
<li>Each observation forms a row.</li>
<li>Each type of observational unit forms a table.</li>
</ol>
<p>In this <a href="http://stackoverflow.com/questions/22695680/python-pandas-timedelta-specific-rows">StackOverflow post</a>, the asker had some data NBA games, and wanted to know the number of days since a team last played. Here's the example data:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span class="kn">import</span> <span class="nn">datetime</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'HomeTeam'</span><span class="p">:</span> <span class="p">[</span><span class="s">'HOU'</span><span class="p">,</span> <span class="s">'CHI'</span><span class="p">,</span> <span class="s">'DAL'</span><span class="p">,</span> <span class="s">'HOU'</span><span class="p">],</span>
                   <span class="s">'AwayTeam'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'CHI'</span><span class="p">,</span> <span class="s">'DAL'</span><span class="p">,</span> <span class="s">'CHI'</span><span class="p">,</span> <span class="s">'DAL'</span><span class="p">],</span>
                   <span class="s">'HomeGameNum'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                   <span class="s">'AwayGameNum'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                   <span class="s">'Date'</span> <span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2014</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2014</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span>
                             <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2014</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">14</span><span class="p">),</span> <span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2014</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">15</span><span class="p">)]})</span>
<span class="n">df</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[1]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AwayGameNum</th>
      <th>AwayTeam</th>
      <th>Date</th>
      <th>HomeGameNum</th>
      <th>HomeTeam</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td> 1</td>
      <td> CHI</td>
      <td> 2014-03-11</td>
      <td> 1</td>
      <td> HOU</td>
    </tr>
    <tr>
      <th>1</th>
      <td> 1</td>
      <td> DAL</td>
      <td> 2014-03-12</td>
      <td> 2</td>
      <td> CHI</td>
    </tr>
    <tr>
      <th>2</th>
      <td> 3</td>
      <td> CHI</td>
      <td> 2014-03-14</td>
      <td> 2</td>
      <td> DAL</td>
    </tr>
    <tr>
      <th>3</th>
      <td> 3</td>
      <td> DAL</td>
      <td> 2014-03-15</td>
      <td> 2</td>
      <td> HOU</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 5 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I want to focus on the second of the three criteria: <em>Each observation forms a row.</em>
Realize that the structure your dataset should take reflects the question you're trying to answer.
For the SO question, we want to answer "How many days has it been since this team's last game?"
Given this context what is an observation?</p>
<hr>
<p>We'll define an observation as a team playing on a day.
Does the original dataset in <code>df</code> satisfy the criteria for tidy data?
No, it doesn't since each row contains <strong>2</strong> observations, one for the home team and one for the away team.</p>
<p>Let's tidy up the dataset.</p>
<ul>
<li>I repeat each row (once for each team) and drop the game numbers (I don't need them for this example)</li>
<li>Select just the new rows (the one with odd indicies, <code>%</code> is the <a href="http://en.wikipedia.org/wiki/Modulo_operation">modulo operator</a> in python)</li>
<li>Overwrite the value of <code>Team</code> for the new rows, keeping the existing value for the old rows</li>
<li>rename the <code>HomeTeam</code> column to <code>is_home</code> and make it a boolen column (True when the team is home)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span class="n">s</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'Date'</span><span class="p">,</span> <span class="s">'HomeTeam'</span><span class="p">,</span> <span class="s">'AwayTeam'</span><span class="p">]]</span><span class="o">.</span><span class="n">reindex_axis</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'AwayTeam'</span><span class="p">:</span> <span class="s">'Team'</span><span class="p">})</span>

<span class="n">new</span> <span class="o">=</span> <span class="n">s</span><span class="p">[(</span><span class="n">s</span><span class="o">.</span><span class="n">index</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)]</span>

<span class="n">s</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">new</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s">'Team'</span><span class="p">]</span> <span class="o">=</span> <span class="n">new</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s">'HomeTeam'</span><span class="p">]</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'HomeTeam'</span><span class="p">:</span> <span class="s">'is_home'</span><span class="p">})</span>
<span class="n">s</span><span class="p">[</span><span class="s">'is_home'</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="s">'Team'</span><span class="p">]</span> <span class="o">==</span> <span class="n">s</span><span class="p">[</span><span class="s">'is_home'</span><span class="p">]</span>
<span class="n">s</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>is_home</th>
      <th>Team</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td> 2014-03-11</td>
      <td> False</td>
      <td> CHI</td>
    </tr>
    <tr>
      <th>1</th>
      <td> 2014-03-11</td>
      <td>  True</td>
      <td> HOU</td>
    </tr>
    <tr>
      <th>2</th>
      <td> 2014-03-12</td>
      <td> False</td>
      <td> DAL</td>
    </tr>
    <tr>
      <th>3</th>
      <td> 2014-03-12</td>
      <td>  True</td>
      <td> CHI</td>
    </tr>
    <tr>
      <th>4</th>
      <td> 2014-03-14</td>
      <td> False</td>
      <td> CHI</td>
    </tr>
    <tr>
      <th>5</th>
      <td> 2014-03-14</td>
      <td>  True</td>
      <td> DAL</td>
    </tr>
    <tr>
      <th>6</th>
      <td> 2014-03-15</td>
      <td> False</td>
      <td> DAL</td>
    </tr>
    <tr>
      <th>7</th>
      <td> 2014-03-15</td>
      <td>  True</td>
      <td> HOU</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 3 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have a 1:1 correspondance between rows and observations, answering the question is simple.</p>
<p>We'll just group by each team and find the difference between each consecutive <code>Date</code> for that team.
Then subtract one day so that back to back games reflect 0 days of rest.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span class="n">s</span><span class="p">[</span><span class="s">'rest'</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Team'</span><span class="p">)[</span><span class="s">'Date'</span><span class="p">]</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span> <span class="o">-</span> <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">s</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>

<div class="output_html rendered_html output_subarea output_execute_result">
<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>is_home</th>
      <th>Team</th>
      <th>rest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td> 2014-03-11</td>
      <td> False</td>
      <td> CHI</td>
      <td>   NaT</td>
    </tr>
    <tr>
      <th>1</th>
      <td> 2014-03-11</td>
      <td>  True</td>
      <td> HOU</td>
      <td>   NaT</td>
    </tr>
    <tr>
      <th>2</th>
      <td> 2014-03-12</td>
      <td> False</td>
      <td> DAL</td>
      <td>   NaT</td>
    </tr>
    <tr>
      <th>3</th>
      <td> 2014-03-12</td>
      <td>  True</td>
      <td> CHI</td>
      <td>0 days</td>
    </tr>
    <tr>
      <th>4</th>
      <td> 2014-03-14</td>
      <td> False</td>
      <td> CHI</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>5</th>
      <td> 2014-03-14</td>
      <td>  True</td>
      <td> DAL</td>
      <td>1 days</td>
    </tr>
    <tr>
      <th>6</th>
      <td> 2014-03-15</td>
      <td> False</td>
      <td> DAL</td>
      <td>0 days</td>
    </tr>
    <tr>
      <th>7</th>
      <td> 2014-03-15</td>
      <td>  True</td>
      <td> HOU</td>
      <td>3 days</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I planned on comparing that one line solution to the code needed with the messy data.
But honestly, I'm having trouble writing the messy data version.
You don't really have anything to group on, so you'd need to keep track of the row where you last saw this team (either in <code>AwayTeam</code> or <code>HomeTeam</code>).
And then each row will have two answers, one for each team.
It's certainly possible to write the necessary code, but the fact that I'm struggling so much to write the messy version is pretty good evidence for the importance of tidy data.</p>

</div>
</div>
</div>
    </div>
  </div>

            </div>
        </div>
            <nav class="postindexpager">
        <ul class="pager">
            <li class="previous">
                <a href="index.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1.html" rel="next">Older posts</a>
            </li>
        </ul>
        </nav>

    
                    <footer id="footer" role="contentinfo">
            <p>Contents © 2015         <a href="mailto:tom.w.augspurger@gmail.com">Tom Augspurger</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer>

        </div>
    </section>
    
    
                <script src="assets/js/all-nocdn.js" type="text/javascript"></script>
    
<!-- Social buttons -->
<div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
<a class="addthis_button_more">Share</a>
<ul>
<li>
<a class="addthis_button_facebook"></a>
</li>
<li>
<a class="addthis_button_google_plusone_share"></a>
</li>
<li>
<a class="addthis_button_linkedin"></a>
</li>
<li>
<a class="addthis_button_twitter"></a>
</li>
</ul>
</div>
<script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
<!-- End of social buttons -->


        <script type="text/javascript">
            $(function(){
                $('.timeago').timeago();
            });
        </script>
</body>
</html>
