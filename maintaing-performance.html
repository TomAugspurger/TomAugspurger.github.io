<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="/theme/css/style.less">
  <script src="//cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="icon" type="image/vnd.microsoft.icon" href="/">
  <link rel="stylesheet" type="text/css" href="/theme/css/normalize.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Roboto+Mono">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/hatena-bookmark-icon.css">
  <link rel="stylesheet" type="text/css" href="theme/css/custom.css">


  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Tom Augspurger">
  <meta name="description" content="Posts and writings by Tom Augspurger">

  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="datas-frame Atom" />

<meta name="keywords" content="pandas">

  <title>
    datas-frame
&ndash; Maintaing Performance  </title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48304175-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<body>
  <main>
    <header>
      <div class="site-name">
        <a href="">datas-frame</a>
      </div>
      <p>
        <a href="/archives.html"><i class="fa fa-archive"></i> Archive</a>
      </p>
    </header>

<article>
  <div class="article__title">
    <h1><a href="/maintaing-performance.html">Maintaing Performance</a></h1>
  </div>
  <div class="article__meta">
    <p class="article__meta__post-date">Posted on: Wed 01 April 2020</p>
 Tags:
      <a href="/tag/pandas.html">#pandas</a>    </p>
  </div>
  <div class="article__text">
    <p>As pandas' <a href="https://pandas.pydata.org/docs/">documentation</a> claims: pandas
provides <em>high-performance</em> data structures. But how do we verify that the claim
is correct? And how do we ensure that it <em>stays</em> correct over many releases.
This post describes</p>
<ol>
<li>pandas' current setup for monitoring performance</li>
<li>My personal debugging strategy for understanding and fixing performance
   regressions when they occur.</li>
</ol>
<p>I hope that the first section topic is useful for library maintainers and the
second topic is generally useful for people writing performance-sensitive code.</p>
<h2>Know thyself</h2>
<p>The first rule of optimization is to measure first. It's a common trap to think
you know the performance of some code just from looking at it. The difficulty is
compounded when you're reviewing a diff in a pull request and you lack some
important context. We use benchmarks to measure the performance of code.</p>
<p>There's a strong analogy between using unit tests to verify the correctness of
code and using benchmarks to verify its performance. Each gives us some
confidence that an implementation behaves as expected and that refactors are not
introducing regressions (in correctness or performance). And just as you use can
use a test runner like <code>unittest</code> or <code>pytest</code> to organize and run unit tests,
you can use a tool to organize and run benchmarks.</p>
<p>For that, pandas uses <a href="https://asv.readthedocs.io/en/stable/">asv</a>.</p>
<blockquote>
<p>airspeed velocity (<code>asv</code>) is a tool for benchmarking Python packages over
their lifetime. Runtime, memory consumption and even custom-computed values
may be tracked. The results are displayed in an interactive web frontend that
requires only a basic static webserver to host.</p>
</blockquote>
<h2>Detecting Regressions</h2>
<p><code>asv</code> is designed to be run continuously over a project's lifetime. In theory, a
pull request could be accompanied with an <code>asv</code> report demonstrating that the
changes don't introduce a performance regression. There are a few issues
preventing pandas from doing that reliably however, which I'll go into later.</p>
<h2>Handling Regressions</h2>
<p>Here's a high-level overview of my debugging process when a performance
regression is discovered (either by ASV detecting one or a user reporting a
regression).</p>
<p>To make things concrete, we'll walk through <a href="https://github.com/pandas-dev/pandas/issues/33012">this recent pandas
issue</a>, where a slowdown was
reported. User reports are often along the lines of</p>
<blockquote>
<p><code>DataFrame.memory_usage</code> is 100x slower in pandas 1.0 compared to 0.25</p>
</blockquote>
<p>In this case, <code>DataFrame.memory_usage</code> was slower with <code>object</code>-dtypes and
<code>deep=True</code>.</p>
<div class="highlight"><pre><span></span>v1.0.3: memory_usage(deep=True) took 26.4566secs

v0.24.0: memory_usage(deep=True) took 6.0479secs

v0.23.4: memory_usage(deep=True) took 0.4633secs
</pre></div>


<p>The first thing to verify is that it's purely a performance regression, and not
a behavior change or bugfix, by <a href="https://github.com/pandas-dev/pandas/issues/33012#issuecomment-603828279">ensuring that the outputs
match</a>
between versions. Sometimes correctness requires sacrificing speed. In this
example, we confirmed that the outputs from 0.24 and 1.0.3 matched, so we
focused there.</p>
<p>Now that we have what seems like a legitimate slowdown, I'll reproduce it
locally. I'll first activate environments for both the old and new versions (I
use <a href="https://conda.io/en/latest/"><code>conda</code></a> for this, one environment per version
of pandas, but <code>venv</code> works as well assuming the error isn't specific to a
version of Python). Then I ensure that I can reproduce the slowdown.</p>
<p><img alt="Comparison of two benchmarks" src="images/performance-comparison.png"></p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">))},</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="o">%</span><span class="n">timeit</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="mf">5.37</span> <span class="n">ms</span> <span class="err">±</span> <span class="mi">201</span> <span class="err">µ</span><span class="n">s</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="err">±</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">100</span> <span class="n">loops</span> <span class="n">each</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">pd</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="s1">&#39;0.25.1&#39;</span>
</pre></div>


<p>versus</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;A&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">))},</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="o">%</span><span class="n">timeit</span> <span class="n">df</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="mf">17.5</span> <span class="n">ms</span> <span class="err">±</span> <span class="mf">98.7</span> <span class="err">µ</span><span class="n">s</span> <span class="n">per</span> <span class="n">loop</span> <span class="p">(</span><span class="n">mean</span> <span class="err">±</span> <span class="n">std</span><span class="o">.</span> <span class="n">dev</span><span class="o">.</span> <span class="n">of</span> <span class="mi">7</span> <span class="n">runs</span><span class="p">,</span> <span class="mi">100</span> <span class="n">loops</span> <span class="n">each</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">pd</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="s1">&#39;1.0.1&#39;</span>
</pre></div>


<p>So we do have a slowdown, from 5.37ms -&gt; 17.5ms on this example.</p>
<p>Once I've verified that the outputs match and the slowdown is real, I turn to
<a href="https://jiffyclub.github.io/snakeviz/">snakeviz</a> (created by <a href="https://twitter.com/jiffyclub">Matt
Davis</a>, which measures performance at the
function-level. For large enough slowdowns, the issue will jump out immediately
with snakeviz.</p>
<p><a href="https://gistcdn.rawgit.org/TomAugspurger/bad09c3e4a03338590545033ad2da925/353fbf67bb1ff7c6f039854af1c2d51cb503c865/pandas-0.25_static.html"><strong>pandas 0.25</strong></a></p>
<iframe title="pandas-0.25 snakeviz"
        width="900px"
        height="600px"
        src="https://gistcdn.rawgit.org/TomAugspurger/bad09c3e4a03338590545033ad2da925/353fbf67bb1ff7c6f039854af1c2d51cb503c865/pandas-0.25_static.html"></iframe>

<p><a href="https://gistcdn.rawgit.org/TomAugspurger/98bc79523187f1fde3093b5af63ae68c/5b1d3815fb2319ff365c3881daeac70bf9077e77/pandas-1.0_static.html"><strong>pandas 1.0</strong></a></p>
<iframe title="pandas 1.0.3 snakeviz"
        width="900px"
        height="600px"
        src="https://gistcdn.rawgit.org/TomAugspurger/98bc79523187f1fde3093b5af63ae68c/5b1d3815fb2319ff365c3881daeac70bf9077e77/pandas-1.0_static.html"></iframe>

<p>From the <a href="https://jiffyclub.github.io/snakeviz/#interpreting-results">snakeviz
docs</a>, these charts
show</p>
<blockquote>
<p>the fraction of time spent in a function is represented by the extent of a
visualization element, either the width of a rectangle or the angular extent
of an arc.</p>
</blockquote>
<p>I prefer the "sunburst" / angular extent style, but either works.</p>
<p>In this case, I noticed that ~95% of the time was being spent in
<code>pandas._libs.lib.memory_usage_of_object</code>, and most of that time was spent in
<code>PandasArray.__getitem__</code> in pandas 1.0.3. This is where a bit of
pandas-specific knowledge comes in, but suffice to say, it looks fishy<sup id="fnref-1"><a class="footnote-ref" href="#fn-1">1</a></sup>.</p>
<p>As an aside, to create and share these snakeviz profiles, I ran the output of
the <code>%snakeviz</code> command through
<a href="https://gist.github.com/jiffyclub/6b5e0f0f05ab487ff607"><code>svstatic</code></a> and
uploaded that as a gist (using <a href="https://github.com/defunkt/gist"><code>gist</code></a>). I
then pasted the "raw" URL to https://rawgit.org/ to get the URL embedded here as
an iframe.</p>
<h2>Line Profiling</h2>
<p>With snakeviz, we've identified a function or two that's slowing things down. If
I need more details on <em>why</em> that's function is slow, I'll use
<a href="https://github.com/rkern/line_profiler">line-profiler</a>. In our example, we've
identified a couple of functions, <code>IndexOpsMixin.memory_usage</code> and
<code>PandasArray.__getitem__</code> that could be inspected in detail.</p>
<p>You point <code>line-profiler</code> one or more functions with <code>-f</code> and provide a
statement to execute. It will measure things about each line in the function,
including the number of times it's hit and how long is spent on that line (per
hit and total)</p>
<div class="highlight"><pre><span></span>In  [9]: %load_ext line_profiler
In [10]: %lprun -f pd.core.base.IndexOpsMixin.memory_usage df.memory_usage(deep=True)
Total time: 0.034319 s
File: /Users/taugspurger/miniconda3/envs/pandas=1.0.1/lib/python3.8/site-packages/pandas/core/base.py
Function: memory_usage at line 1340

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  1340                                               def memory_usage(self, deep=False):
  ...
  1363         1         56.0     56.0      0.2          if hasattr(self.array, &quot;memory_usage&quot;):
  1364                                                       return self.array.memory_usage(deep=deep)
  1365
  1366         1         11.0     11.0      0.0          v = self.array.nbytes
  1367         1         18.0     18.0      0.1          if deep and is_object_dtype(self) and not PYPY:
  1368         1      34233.0  34233.0     99.7              v += lib.memory_usage_of_objects(self.array)
  1369         1          1.0      1.0      0.0          return v
</pre></div>


<p>THe <code>% time</code> column clearly points to <code>lib.memory_usage_of_objects</code>. This is a
Cython function, so we can't use <code>line-profiler</code> on it. But we know from the
snakeviz output above that we eventually get to <code>PandasArray.__getitem__</code></p>
<div class="highlight"><pre><span></span>In [11]: %lprun -f pd.arrays.PandasArray.__getitem__ df.memory_usage(deep=True)
Timer unit: 1e-06 s

Total time: 0.041508 s
File: /Users/taugspurger/miniconda3/envs/pandas=1.0.1/lib/python3.8/site-packages/pandas/core/arrays/numpy_.py
Function: __getitem__ at line 232

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   232                                               def __getitem__(self, item):
   233     10000       4246.0      0.4     10.2          if isinstance(item, type(self)):
   234                                                       item = item._ndarray
   235
   236     10000      25475.0      2.5     61.4          item = check_array_indexer(self, item)
   237
   238     10000       4394.0      0.4     10.6          result = self._ndarray[item]
   239     10000       4386.0      0.4     10.6          if not lib.is_scalar(item):
   240                                                       result = type(self)(result)
   241     10000       3007.0      0.3      7.2          return result
</pre></div>


<p>In this particular example, the most notable thing is that fact that we're
calling this function 10,000 times, which amounts to once per item on our 10,000
row <code>DataFrame</code>. Again, the details of this specific example and the fix aren't
too important, but the solution was to just stop doing that<sup id="fnref-2"><a class="footnote-ref" href="#fn-2">2</a></sup>.</p>
<p><a href="https://github.com/pandas-dev/pandas/pull/33102">The fix</a> was provided by
<a href="https://github.com/neilkg">@neilkg</a> soon after the issue was identified, and
crucially included a new asv benchmark for <code>memory_usage</code> with object dtypes.
Hopefully we won't regress on this again in the future.</p>
<h2>Workflow issues</h2>
<p>This setup is certainly better than nothing. But there are a few notable
problems, some general and some specific to pandas:</p>
<p>Writing benchmarks is hard work (just like tests). There's the general issue of
writing and maintaining code. And on top of that, writing a good ASV benchmark
requires some knowledge specific to ASV. And again, just like tests, your
benchmarks can be trusted only as far as their coverage. For a large codebase
like pandas you'll need a decently large benchmark suite.</p>
<p>But that large benchmark suite comes with it's own costs. Currently pandas' full
suite takes about 2 hours to run. This rules out running the benchmarks on most
public CI providers. And even if we could finish it in time, we couldn't really
trust the results. These benchmarks, at least as written, really do need
dedicated hardware to be stable over time. Pandas has a machine in my basement,
but maintaining that has been a time-consuming, challenging process.</p>
<p><img alt="Pandas' benchmark server" src="images/benchmark-server.png"></p>
<p>This is my current setup, which stuffs the benchmark server (the black Intel
NUC) and a router next to my wife's art storage. We reached this solution after
my 2 year old unplugged the old setup (on my office floor) one too many times.
Apologies for the poor cabling.</p>
<p>We deploy the benchmarks (pandas and a few other NumFOCUS projects) using
Ansible. The scripts get the benchmarks in place, Airflow to run them nightly,
and supervisord to kick everything off. The outputs are <code>rsync</code>ed over to the
pandas webserver and served at <a href="https://pandas.pydata.org/speed/">https://pandas.pydata.org/speed/</a>. You can see
pandas' at <a href="https://pandas.pydata.org/speed/pandas">https://pandas.pydata.org/speed/pandas/</a>. If this seems like a house
of cards waiting to tumble, that's because it is.</p>
<p>Pandas has applied for a NumFOCUS small development grant to improve our
benchmark process. Ideally maintainers would be able to ask a bot <code>@asv-bot run
-b memory_usage</code> which would kick off a process that pulled down the pull
request and ran the requested benchmarks on a dedicated machine (that isn't
easily accessible by my children).</p>
<h2>Recap</h2>
<p>To summarize:</p>
<ol>
<li>We need benchmarks to monitor performance</li>
<li>We use tools like <code>asv</code> to organize and benchmarks continuously</li>
<li>When regressions occur, we use <code>snakeviz</code> and <code>line-profiler</code> to diagnose the
   problem</li>
</ol>
<div class="footnote">
<hr>
<ol>
<li id="fn-1">
<p>PandasArray is a very simple wrapper that implements pandas'
  ExtensionArray interface for 1d NumPy ndarrays, so it's essentially just an
  ndarray. But, crucially, it's a Python class so it's getitem is relatively
  slow compared to numpy.ndarray's getitem.&#160;<a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn-2">
<p>It still does an elementwise getitem, but NumPy's <code>__getitem__</code> is much
  faster than <code>PandasArray</code>'s.&#160;<a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>

</article>


  </main>
    <footer>
      <div class="author__logo">
          <img src="/theme/images/logo.png" alt="logo">
      </div>
      <section class="author">
        <div class="author__name">
          <a href="/pages/about.html">Tom Augspurger</a>
          <p></p>
        </div>
        <div class="author__link">
          <ul>
            <li><a href="/pages/about.html" title="About"><i class="fa fa-link"></i></a></li>
            <li><a href="/pages/article-1-cluster.html" title="article-1-cluster"><i class="fa fa-link"></i></a></li>
            <li>
              <a href="/feeds/all.atom.xml" target="_blank" title="Feed">
                <i class="fa fa-rss"></i>
              </a>
            </li>
          </ul>
        </div>
      </section>
      <div class="ending-message">
        <p>&copy; Tom Augspurger. Powered by <a href="http://getpelican.com" target="_blank">Pelican</a>, Theme is using <a href="https://github.com/laughk/pelican-hss" target="_blank">HSS</a>. </p>
      </div>
    </footer>
</body>
</html>